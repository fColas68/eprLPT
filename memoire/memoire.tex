% ######################################################################
%
% 			PREAMBULE
%
% ######################################################################

% -------------------------------------------------------
% Ce document est un raport. cinquantaine de pages / plusieurs sections
% -------------------------------------------------------
\documentclass[a4paper,12pt]{report}

% -------------------------------------------------------
% Utiliser latin1 pour les accents
% ne pas utiliser utf8 et Latex n'aime pas utf8 ET latin1
%\usepackage[utf8]{inputenc}
% -------------------------------------------------------
\usepackage[utf8]{inputenc}

% utiliser plutôt french, frenchb est obsolete
\usepackage[T1]{fontenc}
\usepackage[english,french]{babel}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{array}
\usepackage{booktabs}
\usepackage{diagbox} % barre oblique pour les cellule à 2 entrées
\usepackage[pdftex]{graphicx}
\usepackage{hhline}
\usepackage{hyperref}
\usepackage{lmodern}
\usepackage{multicol}
\usepackage{subcaption}
\usepackage{supertabular}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{xspace}
\usepackage{pdflscape}

% -------------------------------------------------------
% Pour utiliser certains symboles mathématiques (statistiques)
% -------------------------------------------------------
\DeclareMathOperator{\E}{\mathbb{E}} % Espérence / Expectation
\DeclareMathOperator{\V}{\mathbb{V}} % Variance  / Variance

% -------------------------------------------------------
% Annexes
% -------------------------------------------------------
\usepackage[toc,page]{appendix} 
\renewcommand{\appendixtocname}{Annexes}
\renewcommand{\appendixname}{{\sffamily Annexe}} 

% -------------------------------------------------------
% Ajout LP
% -------------------------------------------------------
\usepackage{todonotes}

% -------------------------------------------------------
% Théorèmes
% -------------------------------------------------------
\usepackage{amsthm}
\theoremstyle{plain}				% Choix du style
\newtheorem{theoreme}{Théorème}	% Définition de l'environnement 1
\newtheorem{example}{Exemple}
\theoremstyle{definition}				% Choix du style
\newtheorem{definition}{Définition} %[section]	% Définition de l'environnement définition

% -------------------------------------------------------
% Pour les ALGORITHMES
% linesnumbered	: les lignes sont numérotées
% ruled			: Le caption est en haut et bordé de lignes horizontale
% vlined		: Regroupement des bloc d'instructions par ligne verticales
% -------------------------------------------------------
\usepackage[linesnumbered, ruled, vlined, french]{algorithm2e}

% Commandes en français:
\SetKwInput{KwRes}{R\'esultat}%
\SetKw{WEntree}{\textcolor{red}{Entrée}}
\SetKw{WEntrees}{\textcolor{red}{Entrées}}
\SetKw{WSaisir}{Saisir}
\SetKw{WInitialisation}{\textcolor{red}{Initialisation}}
\SetKw{WTraitement}{\textcolor{red}{Traitement}}
\SetKw{WAssigne}{\textcolor{blue}{prend la valeur}}
\SetKw{WSortie}{\textcolor{red}{Sortie}}
\SetKw{WSorties}{\textcolor{red}{Sorties}}
%
\SetKwIF{Si}{SinonSi}{Sinon}{Si}{alors}{sinon si}{sinon}{fin si}
\SetKwFor{Tq}{Tant que}{faire}{fin tantque}
\SetKwFor{Pour}{Pour}{faire}{fin pour}
\SetKw{WAfficher}{Afficher}
\SetKwRepeat{Repeter}{répéter}{jusqu'à}%
%
\SetKw{Return}{\textcolor{red}{Renvoyer}}%
%
\SetKwProg{Init}{init}{}{}
% mettre les commentaire des algos en bleu

% -------------------------------------------------------
% Pour les ALGORITHMES façon PYTHON
% -------------------------------------------------------
\usepackage{listings}
\lstset{literate={á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1{Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1{à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1{À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1{ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1{Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1{â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1{Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1{œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1{ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1{ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1{€}{{\EUR}}1 {£}{{\pounds}}1}

\lstdefinestyle{stylepython}{
	language=Python,
	basicstyle=\ttfamily,
	commentstyle=\color{red},
	keywordstyle=\color{blue},
	stringstyle=\color{green}, %olive
	numberstyle=\tiny,numbers=left,
	stepnumber=1,numbersep=5pt}

% -------------------------------------------------------
% Information PDF généré
% -------------------------------------------------------
\hypersetup{pdftex, colorlinks=true, linkcolor=blue, citecolor=blue, filecolor=blue, urlcolor=blue, pdftitle=, pdfauthor=Florian Colas, pdfsubject=, pdfkeywords=}

% -------------------------------------------------------
% MACRO
% -------------------------------------------------------
% Pm||Cmax
\newcommand\problemGrahamPm{$P_m||C_{\max}$\xspace}
% P2||Cmax
\newcommand\problemGrahamPII{$P_2||C_{\max}$\xspace}	%apparemment ne supporte pas les chiffres.
% P||Cmax
\newcommand\problemGrahamP{$P||C_{\max}$\xspace}
% Cmax
\newcommand\cmax{$C_{\max}$\xspace}

% Della Croce et Scatamacchia \textnormal{
\newcommand\dcs{Della Croce et Scatamacchia\xspace}

% -------------------------------------------------------
% Dossier des figures
% -------------------------------------------------------
\graphicspath{{./fig/}}

% -------------------------------------------------------
% Ajout L. Philippe
% Utilisation des Todo inline en macro --> tdi
% -------------------------------------------------------
\usepackage{todonotes}
\newcommand{\tdi}[1]{\todo[inline]{{#1}}{}}
\newcommand{\lp}[1]{\todo[author=LP,color=yellow,inline]{#1}}
\newcommand{\lcc}[1]{\todo[author=LCC,color=green,inline]{#1}}
\newcommand{\fco}[1]{\todo[author=FCO,color=teal,inline]{#1}}
\newcommand{\jb}[1]{\todo[author=JB,color=orange,inline]{#1}}

% -------------------------------------------------------
% Information générales (en attendant la page de garde)
% Utilisé par \maketitle
% -------------------------------------------------------
\title{Évaluation d'algorithmes d'ordonnancement}
\author{Florian Colas}
\date{\today}

% ######################################################################
%
% 				DOCUMENT
%
% ######################################################################
\begin{document}

% #######################################################
% Numérotation des pages
% #######################################################
\pagenumbering{roman}

%##################################################################################"
% 	=======================================================
% 	Page de garde
% 	Utilise Information générales
% 	Ecrit le titre + auteur + date
% 	=======================================================
%	maketitle
%##################################################################################"
\begin{titlepage}
%-------------------------------------------
% LOGOS / 
%-------------------------------------------
\begin{center}
\includegraphics[width=3cm]{logo_supfc.png}
\hfill
\parbox{.5\linewidth}{%
	\centering
	Universit\'e de Franche-Comté	\par
	Master 2 I2A	année 2020 / 2021 \par
	Florian Colas / 21512327
	\vspace{.05\textheight}
	\vspace{.05\textheight}
}
\hfill
\includegraphics[width=3cm]{logoUnivFC.png}

%-------------------------------------------
% MODULE
%-------------------------------------------
\vspace{.05\textheight}
{\LARGE\scshape Module PIR\par}

%-------------------------------------------
% TITRE DE L'ETUDE
%-------------------------------------------
\vspace{.05\textheight}
\vspace{.05\textheight}
\vspace{.05\textheight}
{\Huge\bfseries Évaluation d'algorithmes d'ordonnancement\par}

%-------------------------------------------
% SUPERVISEURS
%-------------------------------------------
\vspace{.05\textheight}
\vspace{.05\textheight}
\vspace{.05\textheight}
%Encadrants
\vspace{.05\textheight}
\begin{tabular}{lllcc}
					&Université de Franche-Comté	&	& Encadrant &	Jury 	\\
Laurent Philippe 	& Professeur des Universités 	& 	&  	X		&	X		\\
Louis-Claude Canon 	& Maître de conférence 			& 	&  	X		&	X		\\
Julien Bernard 		& Maître de conférence 			& 	&  	X		&	X		\\
Veronika Sonigo		& Maître de conférence 			&	&			&	X		\\
\end{tabular}
  
\end{center}
\bigskip
\includegraphics[width=3cm]{logoFEMTO_ST.png}
\end{titlepage}
%##################################################################################"
% / page de garde
%##################################################################################"








\section*{Dédicaces} \label{sec:dedicace}
Ce mémoire marque la fin de 5 ans (avec 1 année de pause) d'études en Master 2  
Informatique Avancée et Applications (I2A) effectuées au CTU de Besançon. 
Je voudrais dédier ce document à Léo et Lou qui ont vécu le quinquennat ``Master papa'' avec 
patience et compréhension et 
à Anne-Sophie dont le soutien inconditionnel, la tolérance et l'indulgence 
à mon égard ont rendu possible ce projet. 


\section*{Remerciements} \label{sec:remerciements}
Je tiens à remercier toutes les personnes qui m'ont aidé dans la réalisation de ce projet de recherche ainsi que la rédaction de ce document :
Laurent Philippe, professeur à l'université de Franche-Comté,
Louis-Claude Canon, maître de conférence et 
Julien Bernard, maître de conférence.
Ils ont tous trois su me guider dans les directions et choix à prendre. 
Ils m'ont transmis des informations précieuses concernant le sujet et les questions techniques.
Je les remercie également pour leur disponibilité, leur écoute, et la qualité des échanges qu'on à pu avoir tout au long de la réalisation de ce projet d'initiation.

Et merci à Anne-Sophie pour ses relectures, l'aide à la correction de ce document.


% -------------------------------------------------------
% Table des matières
%
% On renomme en Sommaire (document français)
%
% On définit la profondeur de la table des matières
% -1 partie,    0 Chapitre,
% 1 Section,    2 sous sections,  3 sous sous section
% 4 Paragraphe, 5 Sous paragraphe
%
% Les sections sont numérotées 1 2 3
% -------------------------------------------------------
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\contentsname}{Sommaire}
\setcounter{tocdepth}{3}	% avant 2 pour la table des matières
\setcounter{secnumdepth}{3}	% pour les section sous et sous sous et paragraphes
\tableofcontents


\bigskip

% #######################################################
% Numérotation des pages
% #######################################################
\pagenumbering{arabic}

%\lp{Attention aux majuscules/minuscules dans les listes et après :}
% =======================================================
% 1 INTRODUCTION GENERALE
% =======================================================
\section{Introduction générale} \label{sec:introductionGenerale}

% -------------------------------------------------------
% du plus général Ordonnancement et traitement parallèle 	>
% au plus spécifique P||Cmax vers ouverture					<
% -------------------------------------------------------

% ORDONNANEMENT
La question d’ordonnancement est omniprésente dans la vie pratique, l'industrie, le transport, 
  les institutions, la santé et toutes autres disciplines qui nécessitent une organisation.
  L'ordonnancement consiste à agencer au mieux des tâches, des jobs reliés ou non entre eux 
  pour atteindre un but tout en optimisant un critère particulier. 
Dans la construction d'une maison, depuis la pose de la première dalle jusqu'à la pose du dernier carrelage, 
  tout a été organisé pour réduire au maximum le retard total. 
  Certaines tâches ont pu être effectuées en parallèle (pose de la plomberie, pose de l'électricité)  
  quant à d'autres, elles n'ont pu commencer qu'après l'achèvement d'ouvrages 
  (pose des tuiles après la finition de la charpente). 

% ORDONNANEMENT dans l'informatique
L’ordonnancement intervient aussi dans l'attribution et l'ordre d’exécution des jobs à réaliser par processeur. 
Même pour une machine mono-processeur l'ordre a son importance si des jobs sont liés par des relations de précédences. 
% ORDONNANEMENT dans l'informatique parallèle
La question est d'autant plus essentielle depuis l'apparition des ordinateurs à structure parallèle.
En effet, la composition d'un ensemble de jobs sur plusieurs processeurs, même sans lien entre eux, a des répercutions sur le temps total nécessaire pour exécuter tous ces jobs. 

% Parallélisme
Le parallélisme est un type d'architecture informatique dans lequel plusieurs processeurs exécutent 
  ou traitent une application, un calcul simultanément. 
Cette structure aide à effectuer de grands calculs en divisant la charge de travail entre plusieurs 
  processeurs capables de communiquer et de coopérer.     

% Scheduling
Le calcul de l'attribution de chaque tâche d'un ensemble de jobs aux ressources disponibles 
  dans le but d'optimiser un critère est un algorithme 
  appelé algorithme d'ordonnancement (Scheduling algorithm). 
Ce calcul doit être effectué le plus rapidement possible et donner la réponse d'ordonnancement en 
  adéquation avec ce qui est attendu.


% Scheduling et P||Cmax
Un cas particulier et fréquent d'ordonnancement est le problème \problemGrahamP tel que définit 
  dans la classification à trois champs de Graham \emph{et al.} \cite{graham1979optimization}. 
Le but de \problemGrahamP consiste à planifier un ensemble $J=\{j_1, j_2, \ldots, j_n\}$ de 
  $n$ jobs (ou tâches) indépendants, 
  sur $m$ machines identiques,  
  dans le but d'optimiser le temps total de traitement appelé makespan (noté $C_{max}$).
Le temps nécessaire de réalisation de chaque job $p_i$ $\in P=\{p_1, p_2, \ldots, p_n\}$  
  (avec $1 \leq i \leq n)$ est connu à l'avance. 
Un job commencé est complété sans interruption (non préemptif) 
  et est exécuté par une seule machine. 
Une machine ne traite qu'un seul job à la fois. 

% problématique générale 
Mais, comme l'ont démontré Garey et Johnson, 
  \problemGrahamPII (i.e avec $m = 2$) est un problème NP-Difficile \cite{garey1978strong}, et 
  \problemGrahamP avec $m \geq 3$ est un problème NP-Difficile au sens fort \cite{garey1982computers}.
En plus, \problemGrahamP devient un problème NP-Difficile, du moment que le nombre de machines 
  est fixé \cite{chen1999potts}, comme l'a montré Rothkopf \cite{rothkopf1966scheduling} qui a 
  présenté un algorithme de programmation dynamique.%\fco{voir le type d'algo pseudo-polynomial ?}

Généralement, donner la solution optimale à un problème d'ordonnancement \problemGrahamP n'est pas réaliste. %\jb{J'ajouterais «Dans le cas général»}
La résolution de celui-ci demanderait un temps excessif et donc rédhibitoire.
Comme les machines sont identiques, et travaillent à la même vitesse, la difficulté repose uniquement 
  sur le regroupement des jobs.
La résolution de ce problème d'ordonnancement va reposer sur des méthodes d'approche qui consistent à 
  calculer en temps polynomial une solution ``assez'' proche de la valeur optimale.

Les jobs sont exécutés sans interruption ni coupure. Donc le makespan ne peut pas être inférieur à 
  la taille du jobs le plus long (i.e. $\max_i\{p_i\}$).
  Il ne peut pas être inférieur non plus à la moyenne des tailles des jobs par machine
  i.e. $\frac{1}{m} \sum_{i=1}^{n} p_i$.
Donc toutes les solutions ont une borne minimale \cite{mcnaughton1959scheduling}: \\

  \begin{center}
  $\text{borne}_{min} = \max \{ \max_i\{p_i\}, \frac{1}{m} \sum_{i=1}^{n} p_i \}$
  \label{borneMini}
  \end{center}

L'existence d'une solution qui résout efficacement le problème de manière optimale
  n'est pas pensable, à moins que $P = NP$.
Dans la littérature, l'étude d'ordonnancement est très riche et abondante. 
Le but étant d'améliorer le temps de calcul, et d'approcher le résultat optimal. 
Les solutions proposées sont des heuristiques ou des approximations.

Le but d'une heuristique (du grec \emph{heuriskein}: trouver) est 
  de produire une solution respectant les contraintes du problème et 
  de bonne qualité selon le critère d'optimisation considéré. 
La solution ne sera pas forcément optimale mais une heuristique efficace tente de trouver une 
  solution de bonne qualité suivant le temps de résolution imparti.
Ces algorithmes calculent des solutions dont la borne maximale au pire des cas n'est pas maîtrisée: 
une étude du comportement est nécessaire pour définir cette borne maximale.  
Pour chaque étude de comportement, les notions suivantes sont utilisées :

\begin{itemize}
	% RESULTAT DE L'ALGORITHME A
	\item $C_m^A(J)$ : Le résultat (makespan) de l'ordonnancement
	d'un ensemble $J$ de jobs 
	sur $m$ machines parallèles identiques 
	obtenu par l'algorithme~$A$;

	% RESULTAT OPTIMAL
	\item $C_m^\star(J)$ : Le makespan optimal idéal de l'ordonnancement 
  	d'un ensemble $J$ de jobs 
	sur $m$ machines parallèles identiques;
	
	% RATIO OBTENU/OPTIMAL
	\item $\Gamma(A)=\frac{C_m^A(J)}{C_m^\star(J)}$ : Le ratio d'approximation 
	atteint par l'algorithme $A$ au pire cas.
	
\end{itemize}
   
Parfois, cette borne est arbitrairement large et n'a pas été analysée. Une simulation permet d'obtenir des 
  informations générales sur les tendances.
Parmi les heuristiques les plus étudiées, nous pouvons citer 
  LPT (Longest Time Processing) \cite{graham1966bounds}, 
  LDM (Largest Differencing Method) \cite{karmarkar1982differencing}, 
  COMBINE \cite{lee1988multiprocessor}.
  
\bigskip
%--------------------------------------
% génese du rapport
%--------------------------------------
Ce mémoire prend le texte de \dcs \cite{della2020longest} comme point de départ.    
Ces derniers revisitent l'heuristique LPT en appliquant aux données d'entrée du problème une stratégie gloutonne.  
L'algorithme développé appelé SLACK devient très compétitif par rapport à d'autres heuristiques, 
  tant en complexité en temps qu'en ratio d'approximation. 
Cette conclusion est le résultat d'un protocole expérimental défini dans \cite{iori2008scatter}. 
Les algorithmes sont testés sur des instances basées sur 2 types de générations de nombres pseudo-aléatoires, contenant 10, 50, 100, 500 et 1000 jobs, à planifier sur 5, 10 et 25 machines. 
Pour $n > m$ cela représente 13 points de comparaisons qui permettent aux auteurs de déclarer SLACK comme étant une alternative sérieuse à LPT, LDM et COMBINE. 
Ce résultat est intéressant. En effet la borne d'approximation se rapproche un peu plus de l'optimal. 
Mais ce résultat empirique repose sur un nombre assez restreint d'échantillons. Sont-ils assez représentatifs pour en dégager une conclusion absolue ? Est-ce le comportement général de SLACK (ou tout autre algorithme) d'être le plus efficace s'il l'est pour ces 13 points ? 

Le but de ce document est de répondre à cette question à l'aide des démarches suivantes :

\begin{itemize}
	\item Reproduire le protocole expérimental de \dcs sur les mêmes algorithmes et les 
	  mêmes types d'instances afin de valider sa reproductibilité;
	  
	\item \'{E}largir ce protocole expérimental aux principaux algorithmes mais à d'autres types de générations aléatoires, voire à de vraies archives de listes de tâches et à un spectre plus large de nombres de jobs 
	et de machines.
	  
\end{itemize} 

\bigskip
% -------------------------------------------------------
%PLAN
% -------------------------------------------------------
%\fco{a revoir}
%\lp{Oui tu peux aussi ajouter ce qui a été dit par Julien, à savoir
%  étendre aux principaux algos}
Le chapitre 2 présente un état de l'art au problème \problemGrahamP. La création des listes de temps et les instances sont traitées dans le chapitre 3. Le chapitre 4 abordée l'environnement de tests, avant de présenter en chapitre 5 le résultat de la reproduction du protocole expérimental de \dcs et du protocole élargi. Ce document se termine par une discussion sur les protocoles de tests des heuristiques.

Les annexes abordent certains points importants de l'implémentation des algorithmes et de la création des listes de temps.  

% =======================================================
% 2 Etat de l'art
% =======================================================
\section{\'{E}tat de l'art} \label{sec:etatDeLArt}

%--------------------------------------------------------
%\subsection{Introduction} \label{ssec:etatDeLArtIntroduction}
%--------------------------------------------------------
Le problème d'ordonnancement se pose depuis l'apparition des premières machines parallèles et 
  est d'autant plus d'actualité que les postes personnels sont équipés depuis quelques années 
  de processeurs (CPU) et de cartes graphiques (GPU) multi-c{\oe}urs.
Les centres de calculs sont dotés de parcs assez uniformes et maintenant 
  les clouds, offrent des instances VM qui permettent des environnements 
  d'exécution homogènes.     
L'ordonnancement fait partie de la catégorie des problèmes d'optimisation combinatoire. 
C'est un champ de la recherche opérationnelle, actif depuis plus d'un siècle 
  et abondant dans la littérature. 

%\lp{Pour la suite préciser: ``Pour P||Cmax'' ?}
Pour le problème \problemGrahamP de nombreuses pistes sont explorées. Il est pratiquement impossible de les énumérer toutes. 
Aussi sont présentées ici les plus étudiées et/ou utilisées pour être comparées ou servir de référent.
  
Nous abordons dans l'ordre, certaines heuristiques, un type d'algorithme d'approximation nommé schéma d'approximation en temps polynomial (PTAS) et une résolution du problème basée sur la programmation linéaire.

\subsection{Heuristiques}\label{ssec:Heuristiques}

Les heuristiques représentent la plus grande partie des recherches concernant le problème \problemGrahamP. 
Celles présentées sont basées 
  sur le principe des LS (List Scheduling), 
  sur une stratégie gloutonne,   
  sur le problème bin-packing et  
  sur le problème de partitionnement de nombres. 

\bigskip   
\paragraph{LS (List Scheduling)}
l'idée d'un algorithme d'ordonnancement de liste est de stocker l'ensemble des jobs dans celle-ci, éventuellement les trier dans un ordre particulier et/ou les regrouper selon une règle définie dans le but de leur assigner une priorité. Ces jobs sont ensuite affectés un à un à une machine suivant un principe déterminé. 
Les machines sont toujours occupées tant qu'il existe au moins un job en attente.


LPT Rule (Longest Time Processing) % (algorithme \ref{algo:LPT})
  proposé par Graham \cite{graham1966bounds}, 
  améliore l'algorithme LS. Contrairement à LS, LPT rule ordonne les jobs dans le sens 
  décroissant de leur temps de traitement et 
  affecte le job à la machine la moins chargée à ce moment là. 
LPT a 
  un ratio d'approximation $\Gamma(LPT) \leq \frac{4}{3}-\frac{1}{3 \cdot m}$ et 
  une complexité en temps de $ O(n \log(n) + n \log(m)$).
De fait, sa simplicité d'implémentation et ses caractéristiques d'approximation font 
  de cet algorithme un référent de tests et l'un des plus repris dans la littérature.
  
\bigskip
% -------------------------------------------------------
% ALGO LPT 
% -------------------------------------------------------
\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{

instance de \problemGrahamP, avec 

$m$ machines, 

$n$ jobs et leur temps d'exécution}

\BlankLine % Petit espace
Trier les jobs de l'ensemble $J$ dans l'ordre décroissant de leur temps
d'exécution et ré-indexer l'ensemble de telle manière à obtenir:
$p_1 \geq p_2 \geq \ldots \geq p_n$

\BlankLine % Petit espace
Parcourir la liste et affecter chaque job à la machine la moins
chargée à ce moment là.
% }

\caption{LPT Rule}
\label{algo:LPT}
\end{algorithm}
% -------------------------------------------------------
% /LPT 
% -------------------------------------------------------

\bigskip   
\paragraph{Stratégie gloutonne}
Della Croce et Scatamacchia \cite{della2020longest} revisitent LPT rule dans le but de l'optimiser. 
L'étude est articulée autour du lien qui existe entre le nombre de machines $m$, le nombre de jobs $n$, 
  la relation qu'il peut y avoir entre les deux et la probabilité que LPT donne un résultat au pire cas. 
S'ensuit SLACK, un algorithme basé sur la stratégie gloutonne suivante, avant d’affecter les jobs un à un à la machine la moins chargée à ce moment là :

\begin{itemize}
\item Trier les jobs par ordre décroissant de leur taille;
\item Découper l'ensemble trié en tuples de m jobs;
\item Soit ``slack'' la différence entre la taille du premier job et la taille du dernier job de chaque tuple;
\item Trier l'ensemble des tuples dans l'ordre décroissant de leur ``slack''.  
\end{itemize} 

  SLACK a une complexité en temps de $ O(n \log(n) + n \log(m)$).

\bigskip
% -------------------------------------------------------
% SLACK
% -------------------------------------------------------
\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{

instance de \problemGrahamP, avec 

$m$ machines, 

$n$ jobs et leur temps d'exécution}

%Etape 1
trier la liste des jobs dans l'ordre décroissant des temps nécessaires de traitements \;
%ETAPE 2
réindexer les jobs, de manière à obtenir $p_1 \geq p_2 \geq ... \geq p_n$ \;
%ETAPE 3
découper l'ensemble obtenu en $\lceil \frac{n}{m} \rceil$ tuples de $m$ jobs (ajout
de jobs ``dummy'' de taille nulle pour le dernier tuple, si $n$ n'est
pas un multiple de $m$) \;
%ETAPE 4
considérer chaque tuple avec la différence de temps (``Slack'') entre le
premier job du tuple et le dernier.

$$
\left\{
    \begin{array}{lll}
	\{1, ..., m\} & \{m+1,..., 2 \cdot m\}  &...  \\
   	p_1 - p_m     & p_{m+1}-p_{2 \cdot m}   &...
   	\end{array}
\right\}   	
$$
%STEP 5
trier les tuples par ordre décroissant de ``Slack'' et ainsi former un nouvel ensemble
\tcp{e.g: $\{ \{m+1,..., 2 \cdot m\} \{1, ..., m\}\}$ si $p_{m+1} - p_{2 \cdot m} > p_1 - p_m$.}
%STEP 6
appliquer l'ordonnancement (affectation à la machine la moins chargée à
ce moment là) à l'ensemble ainsi obtenu.
\caption{SLACK\label{algo:SLACK}}
\end{algorithm}
% -------------------------------------------------------
% /SLACK
% -------------------------------------------------------

\bigskip
\paragraph{Bin-Packing}
Un des problèmes semblable à \problemGrahamP est celui de Bin-Packing. 

Soient
\begin{itemize}
  \item un ensemble d'objets à ranger $t_i \in T=\{t_1, t_2, \ldots, t_n\}$, 
  \item les tailles de ces objets $L(t_i)$ (avec $1\leq i \leq n$). 
  \item une taille de bac C.
\end{itemize} 
Un packing est une partition $B < B_1, B_2, ... B_k > $ 
  telle que $L(B_j) \leq C$ 
  (avec $1\leq j \leq k$ et $L(B_j)$ la somme des tailles des objets pacqués dans $B_j$). 
Autrement dit, cela consiste à placer des objets $t_i$ dans des bacs $B_j$ de taille maximum $C$. 
Le problème Bin-Packing qui est NP-Complet, tente de minimiser le nombre de bacs $k$. 

Bin-Packing peut être considéré comme le double de \problemGrahamP 
  car l'ensemble des objets à ranger associés à leur taille et la partition $B$ 
  peuvent être vus respectivement comme 
  un ensemble $J$ de $n$ jobs, leurs tailles propres, 
  et l'ordonnancement recherché sur $m$ machines.
La taille $C$ des bacs correspond au makespan recherché, 
  et le nombre de bacs obtenus au nombre $m$ de machines.
  
\bigskip
Coffman, Garey et Johnson \cite{coffman1978application} utilisent Bin-Packing 
  pour tenter de résoudre \problemGrahamP et proposent 
  l'heuristique MULTIFIT (algorithme \ref{algo:MULTIFIT}). 
Cet algorithme est basé sur FFD 
  (First-Fit-Decreasing, algorithme \ref{algo:FFD}, \cite{rieck2021basic}), 
  un outil (heuristique) de résolution de Bin-Packing. 
Il accepte en entrée un ensemble de tailles d'objets et une taille maximale $C$ de bacs 
  et propose en retour un packing, donc un nombre de bacs $k$.
L'idée de MULTIFIT est de proposer des valeurs de $C$ à FFD, jusqu'à avoir un nombre de bacs $k=m$.
Ceci est réalisée à l'aide d'une recherche dichotomique dont les bornes de départ qui vont confiner $C$ sont : 
\begin{align*}
&\textnormal{borne inférieure} 	&C_l 	&= \max \{ \max_i \{ L(t_i) \}, \frac{1}{m} \cdot L(T) \} \\
& 								& 		& \textnormal{ou rammené au problème \problemGrahamP} \\	 
& 								& C_l 	&= \text{borne}_{min} = \max \{ \max_i\{p_i\}, \frac{1}{m} \sum_{i=1}^{n} p_i \} \\
&\textnormal{borne inférieure} 	&C_u 	&= 2 \cdot C_l 
\end{align*}

MULTIFIT accepte en entrée un ensemble de temps de jobs $P$, 
  un nombre de machines $m$ et 
  un nombre d'itérations $k$ pour la recherche dichotomique.
Selon la taille de l'instance du problème $k$ doit avoir une valeur suffisante pour que 
  MULTIFIT donne une réponse convenable. 
Il est estimé que cette valeur est atteinte pour toute taille d'instance 
  quand $k=7$ \cite{coffman1978application}.
MULTIFIT a 
  un ratio d'approximation $\Gamma(MULTIFIT) \leq 1,220 + 2^{-k}$ et 
  une complexité en temps de $ O(n log(n) + kn log(m)$).
FFD, quant a lui a 
  un ratio d'approximation de $C_m^{FFD}(J) \leq \frac{11}{9} \cdot C_m^\star(J) + \frac{6}{9}$ 
  \cite{dosa2007tight} et une complexité en temps de $ O(n \log(m)$).

\bigskip
% -------------------------------------------------------
% FFD 
% -------------------------------------------------------
\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{

instance de Bin-Packing avec : 

$C$ taille maximale des bacs,
 
un ensemble $T = \{ t_1, t_2, \ldots, t_n\}$ de $n$ objets à ranger (pacquer)
  dont $L(t_i)$ est la taille de chaque objet $t_i$ (avec $1 \leq i \leq n$)  }

\BlankLine % Petit espace

Trier l'ensemble T par ordre décroissant des $L(t_i)$ et  
ré-indexer l'ensemble de telle manière à obtenir:
$t_1 \geq t_2 \geq \ldots \geq t_n$

$NB_b = 0$ \tcp{nombre de bacs}

\Pour {tout objet $t_i$ avec $i = 1,2, \ldots, n$ } {
	\Pour {tout bac existant $B_j$ (avec $j \leq NB_b$)} {
		\Si { $L(t_i) + L(B_j) \leq C$} {
			pacquer $t_i$ dans le bac $B_j$
			
			sortir de la boucle
		}
	}
	\Si { $t_i$ n'a pas été pacqué}{
		incrémenter $NB_b$
		
		Créer un nouveau bac $B_{NB_b}$
		
		pacquer $t_i$ dans $B_{NB_b}$
		 
	}
}
\caption{FFD}
\label{algo:FFD}
\end{algorithm}
% -------------------------------------------------------
% /FFD 
% -------------------------------------------------------

%\fco{verifier la borne sup si ce ne serait pas plutot 
%$\max\left\{\frac{2}{m} \cdot L(T), \max_i\{2 \cdot L(T_i)\} \right\}$ 
%auquel cas serait donc $2 \cdot Cl$.
%Si ce n'est pas le cas, corriger plus haut}

\bigskip
% -------------------------------------------------------
% MULTIFIT 
% -------------------------------------------------------
\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{

$T$ un ensemble de jobs

$m$ un nombre de processeurs

$k$ un nombre d'itérations
}

\BlankLine % Petit espace
borne supérieure: 
$C_u = \max\left\{\frac{2}{m} \cdot L(T), \max_i\{L(T_i)\} \right\}$

borne inférieure: 
$C_l = \max\left\{\frac{1}{m} \cdot L(T), \max_i\{L(T_i)\} \right\}$

\BlankLine % Petit espace
$i=1$

\Tq {$i \leq k$} {
	$C = \frac{C_u + C_l}{2}$
	
	$NB_b = FFD(T,C)$ \tcp{FFD renvoie le nombre de bacs créés}
	
	\Si {$NB_b \leq m$} {
		$C_u = C$
	}
	\Sinon
	{
	 	$C_l = C$
	}
	incrémenter i
}
\BlankLine % Petit espace
\tcp{
Après $k$ itérations, MULTIFIT renvoie $C_u$ 
  qui correspond à la plus petite valeur de $C$
  pour laquelle $FFD[T,C] \leq m$}

\Return {$C_u$}

\caption{MULTIFIT}
\label{algo:MULTIFIT}
\end{algorithm}
% -------------------------------------------------------
% /MULTIFIT  
% -------------------------------------------------------


\bigskip
Lee et Massey \cite{lee1988multiprocessor} améliorent MULTIFIT 
  en utilisant LPT pour 
  calculer la borne supérieure de départ pour réduire l'amplitude de la recherche dichotomique 
  et proposent l'heuristique COMBINE. 
Contrairement à la recherche dichotomique de MULTIFIT 
  qui effectue $k$ itérations, 
  celle de COMBINE s'arrête lorsque 
  la différence des deux bornes est inférieure à $\alpha \cdot A$.
  
$C_u - C_l \leq \alpha \cdot A$

avec  
\begin{align*}
&A = \sum_{i=1}^{n}\left(\frac{p_i}{m}\right)
&\textnormal{(moyenne des poids des jobs par processeur)} \\
&\alpha = 0.005 						
&\textnormal{(constante arbitraire)}
\end{align*}

Le nombre d’itérations $k$ de recherche dichotomique est variable mais n’excède pas 6. 
Or, LPT a déjà tourné une fois, donc $k \leq 7$.
  
COMBINE a 
  un ratio d'approximation $\Gamma(COMBINE) \leq \frac{13}{12} + 2^{-k}$ et 
  une complexité en temps de $ O(n \log(n) + kn \log(m)$).

\bigskip   
% -------------------------------------------------------
% COMBINE
% -------------------------------------------------------
\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{

instance de \problemGrahamP, avec 

$m$ machines, 

$n$ jobs, 

$\alpha$ un coefficient arbitraire ($\alpha =0,005$ par défaut)
}

A = $\sum_{i=1}^{n}(\frac{p_i}{m})$ \;
M $\leftarrow C_m^{lpt}(J)$ \;
\Si {$M \geq 1,5 \cdot A$}
 {
 	$M^\star = M$ \;
 }
\Sinon
 {
	$C_u \leftarrow M$					\;
	$C_l \leftarrow \max \left\{\frac{M}{\frac{4}{3}-\frac{1}{3 \cdot m}},p_1,A \right\}$ \;
	\Tq {$C_u - C_l > \alpha \cdot A$}
	 {
	 appliquer MULTIFIT \;
	 } \tcp{on arrête lorsque $C_u - C_l \leq \alpha \cdot A$}
 }
\caption{COMBINE}
\label{algo:COMBINE}
\end{algorithm}
% -------------------------------------------------------
% /COMBINE  
% -------------------------------------------------------

\bigskip
\paragraph{Partitionnement de nombres}
Un autre problème similaire à l'ordonnancement est le problème de partitionnement de nombres.

Soit un ensemble $E = \{e_1, e_2, \ldots, e_n\}$ de $n$ entiers. 

Le problème de partitionnement de nombres consiste à 
  diviser l'ensemble de départ en $NB_e$ sous-ensembles 
  mutuellement exclusifs et collectivement exhaustifs
  %\lp{pb de phrase sujet au singulier,verbe au pluriel} 
  de sorte que les sommes des nombres dans chaque sous-ensemble 
  soient aussi égales que possible \cite{korf2009multi}.
Ce problème est NP-complet et peut être assimilé au problème 
  d'ordonnancement \problemGrahamP, avec un ensemble 
  $E = P=\{p_1, p_2, \ldots, p_n\}$ de taille de tâches 
  à partitionner en  $NB_e=m$ sous-ensembles i.e. $m$ machines (ou processeurs).

\bigskip
Karmarkar et Karp \cite{karmarkar1982differencing} proposent LDM (Largest Differencing Method) 
  pour deux partitions puis pour $m$ partitions.
Cet algorithme consiste à remplacer les 2 plus grands (Largest) nombres de l'ensemble de $n$ éléments de départ par leur différence (Differencing) pour obtenir un nouvel ensemble de $n-1$ éléments. 
LDM a
  un ratio d'approximation \cite{michiels2003performance} 
  $\Gamma(LDM) \leq \frac{7}{6}$ 
  pour $m=2$,  
  $ \frac{4}{3}-\frac{1}{3 \cdot (m-1)} \leq \Gamma(LDM) \leq \frac{4}{3}-\frac{1}{3 \cdot m}$
  pour $m \geq 3$ 
  et une complexité en temps \cite{michiels2003performance} de $O(n \cdot \log n)$.  

\bigskip  
% -------------------------------------------------------
% LDM 
% -------------------------------------------------------
\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{

Un ensemble $P = \{p_1, p_2, \ldots, p_n\}$ de $n$ nombres positifs réels 
(temps d'exécution des $n$ jobs indépendants).

$m$ un nombre de partitions à obtenir 
(nombre de machines cible) 
}

\BlankLine % Petit espace
Convertir les $n$ $p_i$ en $n$ m-tuples $A_i$ = [ $m-1$ valeurs vides $\{\}$ et $\{p_i\}$] 
\tcp{e.g. pour $m=3$ $p_i$ devient $[\{\}\{\}\{p_i\}]$}

\Pour {$n-1$ itérations}
{
Calculer pour chaque m-tuple $A_i$ la différence $d(A_i)$ 
  entre la plus grande et la plus petite valeur des éléments de $A_i$ et
  considérer $A_a$ et $A_b$ les 2 m-tuples dont les différences 
  $d(A_a)$ et $d(A_b)$ sont les plus grandes

Combiner $A_a$ et $A_b$ en un seul m-tuple $A_{ab}$ en joignant 
  le premier plus petit élément de $A_a$ 
  (peut être un ensemble vide, 
  un élément, 
  ou un ensemble d'éléments provenant de précédentes combinaisons et 
  dont la valeur est la somme des éléments qui le composent)
  avec l'élément de $A_b$ le plus grand, 
  puis,
  le deuxième élément le plus petit de $A_a$ avec le deuxième élément le plus grand de $A_b$,
  et ainsi de suite 
}
\caption{LDM}
\label{algo:LDM}
\end{algorithm}
% -------------------------------------------------------
% /LDM 
% -------------------------------------------------------

\subsection{Approximation}\label{ssec:Approximation}
Contrairement à une heuristique, qui doit être étudiée pour connaître sa borne d'approximation, 
  celle-ci est maîtrisée par un algorithme d'approximation qui fournit une garantie d'approche.

\paragraph{PTAS (Polynomial-Time Approximation Scheme)}
Une famille d'algorithmes d'approximation, les PTAS,   
  regroupe des algorithmes qui calculent, pour tout $\epsilon > 0$ donné 
  une solution proche de l'optimal 
  d'un facteur $(1 + \epsilon)$ pour un problème de minimisation 
  ou $(1 - \epsilon)$ pour un problème de maximisation, 
  en temps polynomial et dépendant de $\epsilon$. 


Hochbaum et Shmoys sont les premiers à proposer un PTAS \cite{hochbaum1987using} 
  adapté au problème \problemGrahamP, PTAS DUAL. 
Cet algorithme prend comme idée de départ MULTIFIT (algorithme \ref{algo:MULTIFIT}) 
  en reformulant le problème Bin-Packing. Soient : 
\begin{itemize}
	\item Un ensemble d'objets $t_i \in T=\{t_1, t_2, \ldots, t_n\}$;
	
	\item Leur taille $L(t_i)$ avec $1 \leq i \leq n$ et $0 \leq L(t_i) \leq 1$;
	
	\item Une taille maximale $C$ des bacs;
		
	\item $T^{\star}(T)$ le Bin-Packing optimal, 
	i.e. le nombre minimum de bacs nécessaires pour l'organisation des pièces de l'ensemble $T$.
	
\end{itemize}    

Le but de l'algorithme proposé est de construire un arrangement Bin-Packing qui utilise au plus $T^{\star}_m$ 
  bacs remplis avec des pièces totalisant une taille au plus de $1+\epsilon$. 
\problemGrahamP et Bin-Packing sont reliés de la façon suivante :

$T^{\star}(\frac{J}{C}\leq m$ si et seulement si $C^{\star}_m \leq C$. 

Donc, la taille minimale des bacs $C^{\star}$ qui correspond au makespan optimal est telle que 
  $T^{\star}\left( \frac{J}{C^{\star}} \right) \leq m$.
Il y a 2 paramètres critiques $m$ (le nombre de machines identiques) et 
  $C$ (la taille des bacs qui est aussi le makespan recherché). 
Ceci est un problème de décision à 2 paramètres $R(p_1, p_2)$ qui se décline en 2 problèmes d'optimisation 
  dont l'un (problème primal) consiste à fixer le premier paramètre pour optimiser l'autre et 
  inversement pour le deuxième (problème dual).

%PRIMAL
le problème primal $(J,\bar{p_1})$ a pour valeur optimale $OPT_P(J,\bar{p_1})$. 
L'algorithme d'approximation pour ce problème $\epsilon-$primal prend en paramètre $p_1$ 
  et optimise $p_2$ de la manière suivante :

\begin{itemize}
	\item $p_1$ est une valeur inférieure ou égale à $\bar{p_1}$;
	\item $p_2$ est une valeur optimisée $PRIMAL_{P,\epsilon} \le (1+\epsilon)\cdot OPT_P(J,\bar{p_1})$.	 
\end{itemize}

%DUAL
Le problème dual $(J,\bar{p_2})$ a pour valeur optimale $OPT_D(J,\bar{p_2})$.
L'algorithme d'approximation pour ce problème $\epsilon-$primal prend en paramètre $p_2$ 
  et optimise $p_1$ de la manière suivante :

\begin{itemize}
	\item $p_1$ est une valeur optimisée $DUAL_{D,\epsilon}(J, \bar{p_2})\le OPT_D(J,\bar{p_2})$;
	\item $p_2$ est une valeur $ \le (1+\epsilon)\cdot \bar{p_2}$.	 
\end{itemize}

Donc, trouver un algorithme $\epsilon-$primal pour le problème primal
peut être réduit à trouver un algorithme $\epsilon-$dual pour le problème dual.

Trouver un algorithme d'approximation $\epsilon-$dual peut être
réduit à trouver un algorithme
d'approximation $\epsilon-$dual pour une instance du problème où la
taille des pièces sont strictement supérieures à $\epsilon$.

De fait, l'intervalle de la taille des pièces (devenu $]\epsilon, 1]$) est
découpé en S = $\lceil \frac{1}{\epsilon^2}\rceil$ sous intervalles
de tailles identiques
$]\epsilon = l_1, l_2], ]l_2, l_3], \ldots , ]l_S, L_{S+1}=1]$.
Chaque bac $P_i$, sera rempli au maximum avec
$\lfloor \frac{1}{\epsilon} \rfloor$ pièces.

Soit $x_k$ avec $1 \le k \le S$ le nombre de pièces d'un bac dont la
taille est comprises dans $]l_k, l_{k+1}]$.
Chaque $x_k$ peut prendre une valeur dans l'intervalle
$[0,\frac{1}{\epsilon}[$

La configuration d'un bac $P_i$ peut être donnée par un s-tuple $(x_1, x_2, \ldots, x_S)$.
Soit $cf(x_1, \ldots ,x_S)$ une configuration dite faisable si 
$\sum_{k=1}^{S}x_k \cdot l_k \le 1$ 
avec $l_k$ de $]l_k, l_{k+1}]$.


Nous avons donc

$L(P_i) = 1 + \epsilon$

Soit $b_k$ avec $1 \le k \le S$ le nombre de pièces utilisées dans
tous les bacs dont la taille appartient à $]l_k, l_{k+1}]$.

Soit $Bins(b_1, b_2, \ldots, b_S)$ le nombre minimum de bacs
nécessaires, lorsqu'il y a $b_k$ pièces de taille $l_k$, et
considérons que le premier bac soit rempli. Nous obtenons:

\[
  Bins(b_1, b_2, \ldots, b_S) = 1 + \underset{cf(x_1, \ldots ,x_S)}{\min} Bins(b_1-x_1, b_2-x_2, \ldots, b_S-x_S)
\]

Ce qui est résolu par programmation dynamique.

Il existe 2 versions d'algorithmes optimisée pour $\epsilon = \frac{1}{5}$ et $\epsilon = \frac{1}{6}$ qui sont présentés en annexe.


\subsection{Programmation linéaire}\label{ssec:programmationLineaire}

Le problème \problemGrahamP s'inscrit parfaitement dans l'énoncé d'un problème de programmation linéaire.
en effet, la fonction objectif qui consiste à minimiser le makespan et les contraintes sont des fonctions linéaires. Les variables et le résultat attendu sont discrets, ce qui rend la résolution du problème difficile. Ces algorithmes donnent une solution faisable exacte.

\paragraph{PA} 
Mokotoff \cite{mokoto1999scheduling} présente un algorithme basé sur
la formulation de la programmation linéaire en utilisant des
variables booléennes d'affectation des jobs à une machine, i.e.\
$x_{ij}$ est égal à 1 si le job $j_j$ est affecté à la machine $m_i$, ou
0 dans le cas contraire.

% Présentation
% ---------------------
\bigskip
La minimisation du makespan peut être posée ainsi:

Minimiser $y$ tel que:

\begin{itemize}
\item $\sum_{i=1}^{m}x_{ij}=1$ \quad pour $1 \leq j \leq n$

Sur toutes les machines, au moins un et un seul $x_j$ est égal à 1.
Un job est affecté à une et une seule machine.

\item $y-\sum_{j=1}^{n}p_j \cdot x_{ij} \geq 0$ \quad pour $1 \leq i \leq m$

Pour une machine donnée, la somme des temps est inférieure ou égale à $y$.
\end{itemize}

\bigskip
Où la valeur optimale de $y$ est $C_{\max}$
et
\[
  x_{ij} =
  \begin{cases}
    1 \textnormal{ si le job $j_j$ est affecté à la machine $m_i$}\\
    0 \textnormal{ sinon.}\\
  \end{cases}
\]

Le programme linéaire est donc composé de
\begin{itemize}
\item $n \cdot m + 1$ variables (les variables $x_{ij}$ et la variable $y$)
\item $n+m$ contraintes
\end{itemize}

La zone $F$ peut être définie ainsi:
\[
  F=\{ (x,y) : x \in B^{n \cdot m}, y \in \mathbb{R_+} : \sum_{i=1}^{m} x_{ij}=1 \forall j;
y-\sum_{j=1}^{n} p_j \cdot x_{ij} \geq 0 \forall i \}
\]

avec
\[
B=\begin{bmatrix}
x_{11}& &x_{n1}\\
& \ddots & \\
x_{1m}& &x_{nm1}
\end{bmatrix}.
\]

Le polytope $P$ relatif à $F$ est défini ainsi:
\[
  P=\{ (x,y) : x \in \mathbb{R_+}^{n \cdot m}, y \in \mathbb{R_+} : \sum_{i=1}^{m} x_{ij}=1 \forall j;
  y-\sum_{j=1}^{n} p_j \cdot x_{ij} \geq 0 \forall i	\}
\]

Il est possible de construire un ensemble fini d'\textbf{inégalités}
\[
  Ax+Dy \leq \overline{b}
\]
telles que
\[
  \min \{y : (x,y) \in F \} = \min \{y : x \in \mathbb{R_+}^{n \cdot m}, y \in \mathbb{R_+} Ax+Dy \leq \underline{b}
\]
% \ensuremath{^\circ} pour le symbole °
NB: une solution
$(x \ensuremath{^\circ} , y\ensuremath{^\circ}) \in P$ doit être
exclue (car n'est pas un vecteur entier) si
$(x\ensuremath{^\circ}, y\ensuremath{^\circ}) \notin P $.

\bigskip

Des \textbf{inégalités transitoires} peuvent être générées (nombre
maximum de jobs par machine)
\[
  \sum_{j \in S_i} x_{ij} \leq L_i \quad (L_i = h-1 \iff S_{j_h} > LB
  \textnormal{ et } S_{j_{(h-1)}} \leq LB)
\]
LB: borne inférieure.

\bigskip

Pour un problème \problemGrahamP, même de taille modeste, le nombre de
variables et contraintes est très important, et certaines sont
inutiles.
L'algorithme va donc utiliser la méthode des plans sécants (Cutting
Plane Method).
\`A chaque itération , des inégalités valides sont générées, puis une
relaxation est exécutée, jusqu'à l'obtention d'une solution faisable.

L'algorithme est présenté en annexe.

\bigskip
%--------------------------------------------------------
%\subsection{Synthèse}\label{ssec:etatDeLArtSynthese}
%--------------------------------------------------------
Nous venons de parcourir les principaux algorithmes et méthodes de tentative de résolution du problème \problemGrahamP, 
  notamment LPT, COMBINE et LDM 
  utilisées dans le document de Della Croce et Scatamacchia \cite{della2020longest} 
  pour comparer les performances de SLACK. 
Le tableau \ref{table:Heuritiques} récapitule les caractéristiques de ces heuristiques qui nous intéressent.

% -------------------------------------------------------
% TABLEAU des heuristiques étudiées dans le rapport
% -------------------------------------------------------
\begin{landscape}
\begin{table}[h] % !! pour éviter qu'il traine au milieu du sommaire !!
\centering
\begin{tabular}{lp{3cm}lll}
% --------------------------
% TITRES
% --------------------------
\hline
algorithme 	
& Domaine 
& [Ref] 
& Complexité en temps 
& Ratio d'approximation
\\
\hline

% LPT ====================================================
LPT Rule 	
& List Scheduling
& \cite{graham1966bounds} 
& $n~\log(n)$ 
& $\frac{4}{3}-\frac{1}{3m}$ 
\\			

% SLACK ==================================================
SLACK
& List Scheduling

  stratégie 
  
  gloutonne
& \cite{della2020longest} 
& $n~\log(n)$ 
& non précisé 
\\

% LDM ===================================================
LDM
&  partitionnement 
& \cite{karmarkar1982differencing} 
& $n~\log(n)$ 
& 	entre $ \frac{4}{3}-\frac{1}{3(m-1)}$	\newline
	et $\frac{4}{3}-\frac{1}{3 m}$ 			\newline
 	pour $m\geq3$
\\ 

% COMBINE ================================================
COMBINE
& bin-packing 
& \cite{lee1988multiprocessor} 
& $ n~\log(n) + kn~\log(m)$ 
& $\frac{13}{12} + 2^{-k}$ 
\\
\hline
MULTIFIT 	&	bin-packing
 
				composante de COMBINE
& \cite{lee1988multiprocessor} 
& $ n~\log(n) + kn~\log(m)$ 
& $\frac{13}{12} + 2^{-k}$ 
\\
FFD
& bin-packing
		
  composante de MULTIFIT 
& \cite{lee1988multiprocessor} 
& $ n~\log(n) + kn~\log(m)$ 
& $\frac{13}{12} + 2^{-k}$ 
\\

%---------------------------
\hline
\end{tabular}
\caption{Heuristiques étudiées}
\label{table:Heuritiques}
\end{table}
\end{landscape}

%\lp{Domaine pour LPT et SLACK = Liste Scheduling ?}
%\lp{Mettre les complexités sur 2 lignes pour que le tableau tienne mieux dans la page ?} pas possible avec math et tabular 

% =======================================================
% 3 LISTES DE TEMPS / INSTANCES
% =======================================================
\section{Listes de temps et instances} \label{sec:listeTempsInstances}
%--------------------------------------------------------
% \subsection{Introduction}\label{ssec:instancesIntroduction}
%--------------------------------------------------------
Les instances, paramètres de chaque algorithme, reposent sur des listes de temps de jobs.
Le résultat de la comparaison de ces heuristiques dépend de cette liste de temps, de la distribution, 
  de l'hétérogénéité ou de l'homogénéité de ses valeurs. 
Il est important de pouvoir caractériser ces listes de temps pour faire un lien avec le comportement 
  des heuristiques. 
Mais pour des caractéristiques identiques les comportements ne sont pas forcément identiques. 
En effet, une même valeur d'une caractéristique peut représenter plusieurs ensembles de 
  valeurs de temps différentes et ainsi impliquer des comportements algorithmiques différents. 
Il est donc nécessaire de multiplier les tests pour voir se dessiner des tendances, 
  des liens entre distributions de valeurs, caractéristiques, et résultats obtenus.

C'est précisément ce que font \dcs en générant 10 instances de 2 différents types de 
  génération de listes de temps pour chaque couple $\{m,n\}$. 
%\lp{Pas de verbe dans cette phrase}
Cette méthode paraît correcte pour le nombre d'instances mais le cas échéant insuffisante pour les types de listes de temps. 
Le nombre restreint des lois statistiques utilisées dans leur modèle expérimental ne permet pas 
  d'affirmer ou d'infirmer que SLACK n'est pas sensible à la répartition des nombres constituant 
  les listes de temps. 
Pour cela, il est nécessaire de tester SLACK, ou tout autre algorithme, sur des instances aux caractéristiques variées.


Il existe deux façons d'obtenir des listes de temps de jobs :  
Soit les créer entièrement à partir d'un nombre $n$ désiré; Soit les récupérer.

Pour la création d'une liste synthétique des générateurs de nombres aléatoires suivant des lois statistiques différentes peuvent être utilisés.  
\dcs pour leur protocole ont adopté deux types de générations de listes de temps: 
  une répartition uniforme et non-uniforme.
Il est intéressant d'étendre ce protocole à d'autres types de listes.

Pour la récupération, des sites internet mettent à disposition au téléchargement des listes de temps soit synthétiques, soit réelles. 
  
\bigskip
%--------------------------------------------------------
% plan
%--------------------------------------------------------
Après une présentation des choix effectués sur les méthodes d'acquisition des listes de temps, 
nous aborderons les différentes lois statistiques utilisées pour générer des listes de nombres synthétiques 
et le moyen  pour en récupérer des réelles. Ensuite, nous examinerons une méthode de transformation d'une liste de temps en une instance dont l'optimal est connu, pour finir sur la caractérisation des listes de nombres.  


\subsection{Choix de production des listes de temps}\label{ssec:instancesChoixProduction}

%\lp{Dire d'abord que tu veux reproduire les expés de \dcs 
% pour les valider car la reproductibilité des expés est un facteur de qualité}
Nous souhaitons d'abord valider la reproductibilité du protocole expérimental de \dcs. Nous devons donc reproduire les expériences avec les mêmes types de génération de nombres qu'ils utilisent : 
\begin{itemize}
	\item Uniforme; 
	\item Non-uniforme.
\end{itemize}

Selon la taxonomie des distributions statistiques \cite{nielsen2009statistical} il existe plusieurs familles. 
Pour la génération de listes de temps, nous utilisons des variables statistiques indépendantes et 
  identiquement distribuées (i.i.d.) qui suivent pour chaque production la même loi de probabilité.

Dans le but d'élargir ce protocole et de comparer SLACK avec d'autres types de listes de temps 3 autres distributions qui font partie de la famille des distributions exponentielles 
(figure \ref{fig:taxonomieLoisStatistiques}) sont implémentées :
\begin{itemize}
	\item Exponentiel;
	\item Gamma;
	\item Beta.
\end{itemize}

%--------------------------------------------------------
% Figure de taxonomie des lois statistiques (flotante)
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{taxonomieLoisStatistiques.png}
\caption{Taxonomie des lois statistiques utilisées \cite{nielsen2009statistical}.}
\label{fig:taxonomieLoisStatistiques}
\par}
\end{figure}

Pour soumettre les algorithmes à des données de situations réelles,
notre choix se porte sur la récupération (téléchargement) d'archives
existantes de listes de temps provenant des activités de vrais systèmes informatique :
%\lp{Dire ce que c'est}
\begin{itemize}
	\item PWA (Parallel Workload Archive).
\end{itemize}


\subsection{Génération des listes de temps synthétiques}\label{ssec:instancesGenerationListesTempsSynthetiques}
Les listes synthétiques sont créées de toutes pièces en suivant des lois statistiques et de distributions particulières. Sont présentées ici les lois exponentielle, gamma, beta et les 2 méthodes utilisées par \dcs, uniforme et non-uniforme.

les informations concernant les lois exponentielles, beta et gamma proviennent du site de Marie Etienne :

\url{https://marieetienne.github.io/CoursHalieut/rappel_loi.html} 

\bigskip
\paragraph{Loi exponentielle} 
ou loi de durée de vie sans vieillissement (figure \ref{fig:LoiStatistiquesExponentielle}).
Soit $X$ une variable aléatoire définie dans $[0, \infty[$. $X$ suit une loi exponentielle de paramètre $\lambda$ si elle a pour densité :


  \begin{center}
  $[X=t] = \left\{
    \begin{array}{ll}
        \lambda e^{-\lambda t}  & \mbox{si } t \geq 0  \\
        0 & \mbox{sinon}
    \end{array}
	\right.$
  \label{definitionLoiExponentielleDensite}
  \end{center}

L’espérance et la variance sont fonctions de $\lambda$ et sont égales a :

\begin{align*}
	\E(X) &= \frac{1}{\lambda} \\
	\V(X) &= \frac{1}{\lambda ^2}
\end{align*} 


%--------------------------------------------------------
% Figure loi de statistique Exponentielle (flotante)
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{loiStatExponentielle.png}
\caption{Loi statistique exponentielle.}
\label{fig:LoiStatistiquesExponentielle}
\par}
\end{figure}

\paragraph{Loi gamma}
ou modélisation de phénomènes qui se déroulent au cours du temps (figure \ref{fig:LoiStatistiquesGamma}). 
La loi de statistique Gamma est une loi de la famille des lois exponentielles à 2 paramètres 
  et se définit sur $[0, \infty]$.
Si $Y_1, Y_2, \ldots, Y_n$ sont des variables i.i.d. 
  de loi exponentielle de paramètre $\lambda$ alors $X=\sum_{ i= 1}^{\alpha} X_i$  
  suit une loi gamma $\Gamma(\alpha, \beta)$ avec 
    $\alpha$ le paramètre de forme et 
    $\beta$ ($=\lambda$) le paramètre d'échelle. 
  
Si X suit une loi $\Gamma(\alpha, \beta)$ alors la densité est de la forme :

  \begin{center}
  $[X=t] = \left\{
    \begin{array}{ll}
    	\frac{\beta^{\alpha} t^{\alpha-1} e^{-\beta t}}{\Gamma(\alpha)}  & 
    	\mbox{si } t \geq 0  \\
        0 & 
        \mbox{sinon}
    \end{array}
	\right.$
  \label{definitionLoiGammaDensite}
  \end{center}
   
Les paramètres $\alpha$ et $\beta$ peuvent être définis aussi ainsi :

   
\begin{align*}
   k 		& \textnormal{ tel que } \alpha = k  \textnormal{ et} \\
   \theta 	& \textnormal{ tel que } \beta  = \frac{1}{\theta}
\end{align*}

L’espérance et la variance sont fonctions de $k$ et $\theta$ et sont égales a :

\begin{align*}
	\E(X) &= k \theta \\
	\V(X) &= k \theta ^2
\end{align*}

%--------------------------------------------------------
% Figure loi de statistique Gamma (flotante)
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{loiStatGamma.png}
\caption{Loi statistique Gamma.}
\label{fig:LoiStatistiquesGamma}
\par}
\end{figure}

\paragraph{Loi beta} (figure \ref{fig:LoiStatistiquesBeta})
La loi Beta a été développée par Thomas Bayes (1702 - 1761) pour répondre à son propre problème 
  de succès/échecs dont la proportion de succès possible est inconnue \cite{bayes1991essay}. Cette proportion inconnue, qui est la variable aléatoire représentée par une loi beta, est déduite par tirages successifs avec remise. 
La loi de statistique Beta est une loi de la famille des lois Exponentielles à 2 paramètres et se définit 
  sur $[0, \infty]$. 
 
% texte traduit de Bayes
%  étant donné un certain nombre de fois où un événement inconnu s'est produit et a échoué : il faut que %la probabilité qu'il se produise lors d'un seul essai se situe quelque part entre deux degrés de %probabilité que l'on peut nommer. 

Si la variable aléatoire X suit une loi Beta de paramètres $\alpha$ et $\beta$ alors la loi de densité est de la forme :
  \begin{center}
  $[X=t] = \left\{
    \begin{array}{ll}
    \frac{\Gamma(\alpha + \beta) t^{\alpha-1} (1-t)^{\beta-1}}{\Gamma(\alpha) \Gamma(\beta)}
    & 
   	\mbox{si } t \in [0,1]  \\
        0 & 
        \mbox{sinon}
    \end{array}
	\right.$
  \label{definitionLoiBetaDensite}
  \end{center}

Beta est intéressante dans l'analyse de proportions d’événements de type succès/échec ou
(moyennant un changement d'échelle) dans la modélisation du temps avant la fin d'une tâche.

L’espérance et la variance sont fonctions de $\alpha$ et $\beta$ et sont égales a :

\begin{align*}
	\E(X) &= \frac{\alpha}{\alpha + \beta} \\
	\V(X) &= \frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)} 
\end{align*}

%--------------------------------------------------------
% Figure loi de statistique Beta(flotante)
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{loiStatBeta.png}
\caption{Loi statistique Beta.}
\label{fig:LoiStatistiquesBeta}
\par}
\end{figure}



\paragraph{Loi uniforme} 
Cette loi statistique utilisée pas \dcs est non exponentielle. 
Une loi uniforme sur $[a, b]$ est une loi de probabilité $P$ dont la fonction de densité est 
  constante sur $[a, b]$. i.e. les nombres générés sont uniformément répartis dans l'intervalle $[a, b]$

\begin{center}
$[X] = \frac{1}{b-a}$
\end{center}

\paragraph{Liste non-uniforme}
Ce type de génération de liste de temps est utilisé dans le protocole expérimental de \cite{frangioni2004multi} et est repris par \dcs \cite{della2020longest} pour éprouver SLACK.
Une liste de nombres aléatoires générée via une règle NON-UNIFORME de paramètres $a$ et $b$ 
  est l'union de 2 listes générées via une loi uniforme comme suit :

\begin{align*}
	98 \%  &= \textnormal{loi uniforme } [0.9(b-a), b] \\
	2\%    &= \textnormal{loi uniforme } [a, 0.2(b-a)] 
\end{align*}

% \jb{En vrai, ça devrait être $[a + 0.9 (b-a), b]$ et $[a, a + 0.2 (b-a)]$} effectivement ! 

\begin{example}
Pour la génération d'une liste suivant la règle non-uniforme [1, 100], 

\begin{align*}
	98 \%  &\textnormal{ est uniformément répartis sur } [89.1~,~ 100] \\
	2\%    &\textnormal{ est uniformément répartis sur } [1   ~,~ 19.8] 
\end{align*}
ce qui peut donner pour $n = 10$
	$\{95, 95, 90, 93, 97, 89, 90, 90, 99, 2\}$
\end{example}
%\lp{}
Ce qui donne des instances très hétérogènes. 
 
\subsection{Récupération de listes de temps réelles}\label{ssec:instancesGenerationListesTempsReelles}

\paragraph{PWA} Parallel Workload Archive. L'idée est de collecter des données de vrais systèmes et de 
  supposer que les futurs workload seront similaires \cite{feitelson2014experience}.

   
PWA est un dépôt de fichiers journaux de temps disponible à l'URL :

  
\url{https://www.cs.huji.ac.il/labs/parallel/workload/}


Ces archives proviennent de l'enregistrement direct des événements qui se produisent sur les systèmes informatiques et ont l'avantage de représenter un panel de besoins réels. 
Mais elles peuvent comporter certains inconvénients :
%\lp{attention majuscules/minuscules dans la liste}
\begin{itemize}

	\item Le nombre de jobs $n$ n'est pas maîtrisé et ne représente qu'une 
	vingtaine de fichiers, donc un nombre limité de tests et comparaisons empiriques à effectuer;
	
	\item Ces archives ne sont pas forcément complètes et des informations importantes peuvent manquer;
	
	\item Incohérence de données. Certaines informations ne passent pas le con\-trôle de
	contraintes d'intégrités;
	
	\item Données erronées. Des données peuvent être fausses. e.g dues au dépassement d'adressage de nombres;
	
	\item Modification d'environnement. Le problème inhérent aux machines 
	est leur hétérogénéité qui change avec le temps;
	
	\item Comportement non représentatif. L'aspect humain entre aussi en ligne de compte;
	
	\item Effet "END". Les jobs sont consignés une fois terminés. 
	Entre une tâche extrêmement courte et une tâche longue le temps 
	d'enregistrement est le même. Cela peut provoquer un décalage 
	entre la fin du journal et le temps calculé;
	
	\item Les temps d'arrêts ne sont pas consignés. 
	  
\end{itemize}

\subsection{Instance et maîtrise de la solution optimale}
\label{ssec:instancesMaitriseSolutionOptimale}

Pour comparer les résultats obtenus il est nécessaire d'avoir un référent par rapport au Makespan. 
Il n'est pas possible d'obtenir le ratio d'approximation de l'algorithme A ($\Gamma(A)=\frac{C_m^A(J)}{C_m^\star(J)}$) car l'optimal n'est pas connu et c'est précisément ce que l'on cherche. 
La seule donnée connue est la borne minimale de la liste de tailles de jobs.
Or cette borne ($\text{borne}_{min} = \max \{ \max_i\{p_i\}, \frac{1}{m} \sum_{i=1}^{n} p_i \}$) n'est pas forcément l'optimal et le rapport $\frac{Optimal}{\text{borne}_{min}}$ varie.

\bigskip
% Exemple
% ---------------------

\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{MoyenneVsOptimal.jpg}
\caption{Liste de coût de départ, moyenne des tailles des jobs pour 4 machines, et makespan optimal.}
\label{ex:borneMinVSOptimalListeDepart}
\par}
\end{figure}

\begin{example}
Soit $P=\{8, 5, 7, 8, 5, 5\}$, l'ensemble des $p_i$ à appliquer sur 4 machines parallèles identiques.
La borne minimale est:


$$\text{borne}_{min} = \max \left\{ \max_i\{p_i\}, \frac{1}{m} \sum_{i=1}^{n} p_i \right\} = 9.5$$


L'optimal $C_4^\star(J) = 12$ (figure \ref{ex:borneMinVSOptimalListeDepart}).
\end{example}

Cette borne minimale est égale à l'optimal uniquement si toutes les char\-ges des machines sont identiques.
À partir d'une liste de coûts (synthétique ou réelle) il est donc possible d'obtenir une instance dont l'optimal est connu \cite{benoit2021update}. Cette opération nécessite la transformation de la liste de coût de départ pour un nombre de machines défini (figure \ref{ex:maitriseOptimal}).
\begin{itemize}
	\item Soit une liste de $n$ jobs et l'ensemble des $p_i$ à appliquer sur $m$ machines parallèles identiques;
	\item Ordonnancement : chaque job est affecté à la machine la moins chargée à ce moment là;
	\item Tri : tri des machines par ordre décroissant des charges;
	\item Complétion : la machine la plus chargée (la première) représente le makespan. 
	La charge des $m-1$ machines restantes est complétée avec des jobs fictifs pour obtenir 
	le même temps que la machine la plus chargée.
%             \lp{Avec des tâches fictives} pour obtenir le même temps
%             d'exécution que la machine la plus chargée.
%  \jb{Attention à écrire makespan toujours de la même manière tout au long du rapport}
	\item Toutes les machines ont le même temps d'exécution. L'optimal est dans ce cas égal à la 
	      moyenne des temps par machine. 
	      La nouvelle liste de coûts contient désormais $n + m-1$ éléments.
\end{itemize}

La liste de départ est modifiée suite à l'ajout de $m-1$ jobs fictifs. 
Plus le nombre de machines $m$ augmente par rapport à $n$ et plus la distribution utilisée pour 
  la création de la liste de départ est perturbée. 
En effet, les jobs fictifs ajoutés ne répondent pas à la distribution utilisée. 
Il est donc possible qu'un biais existe entre la distribution de départ et l'instance complété avec $m-1$ jobs.

 
Il convient de distinguer la liste de coût native obtenue 
  soit par génération, 
  soit par récupération, 
  dont seule la borne minimale est connue  
  et liste complétée avec $m-1$ temps de jobs nommée M1 qui est une instance dont l'optimal est connu.
  
Tous les protocoles expérimentaux sont effectués sur les instances M1 et sur le nombre réel de 
  tâches ($n + (m-1)$).

\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{maitriseOptimal.jpg}
\caption{transformation d'une liste pour obtenir l'optimal.}
\label{ex:maitriseOptimal}
\par}
\end{figure}

\bigskip
Nous venons de voir comment les listes de temps sont générées et utilisées. 
Elles peuvent être créées via la production de nombres pseudo-aléatoires selon un nombre 
  défini de jobs et une distribution statistique choisie 
  ou récupérées d'une archive de fichiers journaux de tâches relatifs à de réelles 
  activités de production.
De ces listes peuvent être calculées des instances (M1) dont l'optimal est connu, 
  ce qui va permettre une estimation de l'efficacité des algorithmes.
Et enfin, plusieurs indicateurs statistiques caractérisant chaque instance les accompagnent.

Nous abordons maintenant la notion de ``campagnes'' de tests où les instances sont soumises à des heuristiques.  

% =======================================================
% 4 CAMPAGNES
% =======================================================
\section{Campagnes} \label{sec:Campagnes}

Chaque expérience se déroule en ``campagne''. Une campagne est un ensemble de paramètres expérimentaux 
(liste de nombres de machines, liste de nombres de jobs, type d'instances à créer, algorithmes à comparer) 
qui aboutit à un fichier résultat global pour y être analysé.   

%--------------------------------------------------------
% plan
%--------------------------------------------------------
Ce chapitre aborde l’environnement de tests, le choix des heuristiques implémentés et le déroulement d'une campagne. Est expliqué pour finir, comment les Makespan sont comparés entre eux.

\subsection{Environnement de tests} \label{ssec:campagnesEnvironnementDeTests}

L'environnement de tests est développé 
  en Python pour la partie applicative 
  (génération des listes de temps, calcul de l'instance M1, algorithmes) et 
  en R pour la partie analyse et graphes. 
Des informations sur la plate-forme sont disponibles en annexe.

Toutes les campagnes ont été effectuées sur un portable 
  doté de 4 Go de ram et 
  équipé d'un processeur Intel core I3 4330u cadencé à 1900 MHz.


\subsection{Choix des heuristiques} \label{campagneChoisHeuristiques}

Pour reproduire l'expérience de \dcs et comparer les résultats, les mêmes heuristiques sont implémentées à l'environnement de test. Soit :
\begin{itemize}
	\item LPT rule;
	\item SLACK;
	\item LDM;
	\item COMBINE.
\end{itemize}

Ceci a aussi l'avantage d'expérimenter 4 pistes différentes pour résoudre le problème \problemGrahamP :
\begin{itemize}
	\item LS (list-Scheduling) avec LPT rule; 
	\item Bin-Packing avec COMBINE; 
	\item Stratégie gloutonne avec SLACK; 
	\item Partitionnement de nombres avec LDM.  
\end{itemize}

COMBINE repose sur deux autres heuristiques qui sont aussi implémentées : FFD et MULTIFIT.



\subsection{Déroulement d'une campagne} \label{ssec:campagnesDeroullementDUneCampagne}
L'objectif est de reproduire le protocole expérimental de \dcs et aussi de l'élargir 
  à d'autres types d'instances et de possibilités de comparaisons.
En plus des possibilités de tests sur des instances de 10, 50, 100, 500 et 1000 jobs à planifier 
  sur 5, 10 et 25 machines \cite{della2020longest}, 
  chaque campagne peut faire varier $n$ de 1 en 1 avec 
  un nombre de départ et un nombre d'arrivée 
  ou suivant une liste. 
Il en est de même pour le nombre de machines $m$. 
Les deux valeurs peuvent aussi évoluer conjointement.

%--------------------------------------------------------
% Figure déroulé d'une campagne (flotante)
%--------------------------------------------------------
\begin{figure}
{\centering
%\includegraphics[width=\columnwidth]{derouleCampagne.png} : trop grand sinon!
\includegraphics[height=50mm]{derouleCampagne.png}
\caption{Déroulement d'une campagne.}
\label{fig:deroulementDUneCampagne}
\par}
\end{figure}

Une campagne boucle sur le nombre de machines choisies, le nombre de jobs à créer pour les listes de temps, par nombre et type de loi statistiques. Pour chaque triplet \{$m$, $n$, liste de temps\} sont créées des instances native et M1 qui sont soumises aux algorithmes LPT, SLACK LDM et COMBINE 
 (figure \ref{fig:deroulementDUneCampagne}).

Les 4 algorithmes sont donc exécutés à chaque itération aux mêmes instances i.e aux mêmes valeurs. 

%--------------------------------------------------------
% Figure Contenu fichier RESULT.CSV (flotante)
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{contenuResultCSV.png}
\caption{Contenu du fichier result.csv.}
\label{fig:contenuResultCSV}
\par}
\end{figure}

8 lignes résultat sont générées et sont intégrées dans un fichier global ``result.csv'' une fois les boucles de la campagne terminées pour comparaison (figure \ref{fig:contenuResultCSV}). La structure se décompose ainsi :
\begin{itemize}
	\item \textit{generateMethode} : Est la méthode qui est utilisée pour générer la liste de temps;
	 
	\item \textit{m} : Est le nombre de machines identiques pur les instances Native et M1;
	 
	\item \textit{id} : Est l'id du triplet \{$m$, $n$, numéro de liste de temps\}. 
	Sert aux regroupements et comparaisons des algorithmes pour une même instance;
	
	\item \textit{seed} : Est la graine produit du moteur de génération de nombres pseudo-aléatoires 
	utilisée pour la création de la liste de temps. 
	Peut servir pour recréer à l'identique une instance;
	 
	\item \textit{n} : Nombre de jobs servant à créer une liste de temps native;
	 
	\item \textit{$[a-b]$} : Paramètres a et b pour les listes de temps uniforme et non-uniforme. 
	Cette information est utilisée pour recréer le protocole expérimental de \dcs;
	
	\item \textit{LowBound} : Borne inférieure de l'instance native;
	
	\item \textit{m1\_n} : Nouveau nombre de jobs de l'instance M1 après complétion et calcul de l'optimal;
	
	\item \textit{m1LowBound} : Borne inférieure de l'instance M1;
	
	\item \textit{m1Optimal} : Optimal calculé sur l'instance M1;
	
	\item \textit{resultConcerns} : Indique si le Makespan calculé concerne l'instance native ou M1;
	
	\item \textit{algoName} : Nom de l'algorithme soumis;
	
	\item \textit{makespan} : Makespan trouvé par l'algorithme soumis;
	
	\item \textit{time} : Temps qu'il a été nécessaire pour calculer le makespan	par l’algorithme. 
\end{itemize}

\subsection{Comparaison Makespan et normalisation}
 \label{ssec:campagnesComparaisonMakespanNormalisation}

Comparer les makespans sous leur forme brute n'est pas significatif. 
Les valeurs obtenues sont fonction du contenu des instances.

Il est donc nécessaire de normaliser le résultat pour permettre des comparaisons. 3 pistes sont explorées :
\begin{itemize}

  \item $\frac{Makespan}{borne~inférieure}$ : Seule piste possible de normalisation 
  des instances natives car seule leur borne inférieure sont connues. 
  C'est la normalisation qui serait utilisée pour comparer les algorithmes sur des instances natives. 
  Mais celles-ci ne sont utilisées que pour calculer des instances M1. 
  
  \item Makespan - Optimal : Ou makespan absolu \cite{benoit2021update}. 
  Permet de retirer du résultat l'optimal connu de l'instance M1.
  Cette valeur tend vers $0$ lorsque le résultat converge vers l'optimal 
  mais ne permet pas une comparaison avec 
  le ratio d'approximation $\Gamma(A)=\frac{C_m^A(J)}{C_m^\star(J)}$;

  \item $\frac{Makespan}{Optimal}$ : Ou makespan relatif \cite{benoit2021update}.
  Permet d'obtenir le rapport entre le makespan calculé et l'optimal de l'instance M1.
  Cette valeur tend vers $1$ lorsque le résultat converge vers l'optimal. 
  Cette normalisation permet aussi une comparaison avec  
  le ratio d'approximation $\Gamma(A)=\frac{C_m^A(J)}{C_m^\star(J)}$. 
  Cette normalisation est donc utilisée pour comparer les résultats obtenus sur les instances M1.
  
\end{itemize}


% =======================================================
% 5 RESULTATS
% =======================================================
\section{Résultats} \label{sec:resultats}

\lp{Dans la suite on utilise que des instances M1 ?}

\subsection{Protocole expérimental de Della Croce et Scatamacchia}
\label{ssec:resultatsPrtocoleExperimentalDellaCroceScatamacchia}
 
Pour comparer SLACK aux autres heuristiques LPT LDM et COMBINE, \dcs 
 utilisent 10 instances uniformes et non-uniformes d'intervalle [a, b] de [1, 100], [1, 1000] et [1, 10000] 
 pour un nombre de machines de 5 et un nombre de jobs de 10, 50, 100, 500 et 1000, et sur un nombre de machines de 10 et 25 pour un nombre de jobs de 50, 100, 500 et 1000.
soit un total de : 

pour chaque intervalle [a, b] = [1, 100], [1, 1000], [1, 10000] et
  chaque classe uniforme et non-uniforme. 
\begin{itemize}
\item 10 instances $\cdot$ 5 couples $\{m=5,n\}$: \\ $\{5,10\},\{5,50\},\{5,100\},\{5,500\},\{5,1000\}$;
\item 10 instances $\cdot$ 4 couples $\{m=10, n\}$: \\ $\{10,50\},\{10,100\},\{10,500\},\{10,1000\}$;
\item 10 instances $\cdot$ 4 couples $\{m=25,n\}$: \\ $\{25,50\},\{25,100\},\{25,500\},\{25,1000\}$.
\end{itemize}  

780 instances.

%\lp{Pour le tableau iL faut expliquer W/E/L}

%--------------------------------------------------------
% Figure resultat obtenu par DCS (non flottant
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{1_Resultat_De_DCS.pdf}
%\includegraphics[height=100mm]{1_Resultat_De_DCS.png}
\caption{Résultat obtenu par Della Croce et Scatamacchia.}
\label{fig:resultatDellaCroceScatamacchia}
\par}
\end{figure}

La figure \ref{fig:resultatDellaCroceScatamacchia} présente le résultat obtenu dans \cite{della2020longest}.

Le principe est de compter combien de fois SLACK calcule un makespan plus proche de l'optimal que LPT, LDM ou COMBINE.
Lorsqu'il gagne contre un algorithme, un point W (win) est comptabilisé. 
Lorsqu'il perd, un point L (loose) est comptabilisé.
Lorsqu'il est équivalent à l'algorithme avec lequel il se mesure, un point E (equivalent) est comptabilisé.   
 
Les auteurs annoncent une amélioration significative de LPT avec SLACK 
  car celui-ci est meilleur à 65.8\% des cas contre LPT suivant les 780 instances 
  de référence de la littérature \cite{della2020longest}. 
De ce fait, SLACK peut être vu comme une alternative précieuse à LPT.
  
  
\subsection{SLACK sur des instances réelles}
\label{ssec:resultatsSLACKReel}

%--------------------------------------------------------
% Figure resultat obtenu par DCS (flottant)
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{2_Resultat_reel.pdf}
\caption{Makespan obtenu par heuristique sur 5 archives PWA pour 5, 10, 25 machines.}
%\jb{Qu'est-ce que représentent ces nombres? Il faut le dire dans le titre}
\label{fig:resultat5PWA}
\par}
\end{figure}
 
 Les 4 algorithmes sont exécutés sur des listes de temps réelles, provenant de 5 PWA NASA IPSC, Early CTC SP2, LANL CM5, SDSC Par95 et SDSC Par96, qui contiennent respectivement 18066, 75895, 122058, 32128 et 53744 jobs. Ces 5 archives sont transformées en instances de 5, 10 et 25 machines et le résultat (makespan relatif) est présenté en figure~\ref{fig:resultat5PWA}.
 
SLACK est efficace mais de très peu. 
Les heuristiques dans cet échantillon sont plus souvent équivalentes.  
 
\subsection{Reproduction du protocole expérimental de Della Croce et Scatamacchia}
\label{ssec:resultatsReroductionPrtocoleExperimentalDellaCroceScatamacchia}
 
%--------------------------------------------------------
% Figure resultat obtenu par REPRODUCTION DU PROTOCOLE DE DCS
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{3_Resultat_Reproduction_De_DCS.pdf}
\caption{Résultat obtenu par reproduction Della Croce et Scatamacchia.}
\label{fig:resultatReproductionDellaCroceScatamacchia}
\par}
\end{figure}

Le même protocole expérimental est exécuté. Le résultat est indiqué 
  figure~\ref{fig:resultatReproductionDellaCroceScatamacchia}.
Les résultats obtenus ne sont pas tout à fait identiques ou avoisinants. 
  
Côté temps, SLACK passe d'un facteur 1.3 à un facteur 1.5 par rapport à LPT. 
Mais c'est COMBINE qui a le plus de différence en passant d'un facteur 1.40 
  à un facteur 3.9 par rapport à LPT. 
Cela peut être du à l'implémentation des algorithmes et à la technologie utilisée. 

Côté makespan, SLACK cumule plus de victoires contre LPT en passant de 65.8\% à 82.3\% de ``WIN''.
Par contre, SLACK perd de son efficacité contre LDM et surtout contre COMBINE. COMBINE qui récupère 36.3\% de ``WIN'' contre SLACK, contre 16.5\% précédemment indiqué.


Peut-être que notre protocole est une singularité statistique. L'expérience est exécutée 50 fois pour s'approcher le plus de la tendance la plus représentative.


%--------------------------------------------------------
% Figure resultat obtenu par REPRODUCTION DU PROTOCOLE DE DCS
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{4_Resultat_Reproduction50DCS.pdf}
\caption{Résultat obtenu avec 50 campagnes de tests type ``Della Croce et Scatamacchia''.}
\label{fig:resultatReproduction50DellaCroceScatamacchia}
\par}
\end{figure}

Le résultat est résumé en figure \ref{fig:resultatReproduction50DellaCroceScatamacchia}. 
La tendance des 50 campagnes corrèle le résultat obtenu précédemment et non pas 
  celui de Della Croce et Scatamacchia.

\subsection{Facteurs d'influence sur le comportement des heuristiques}
\label{ssec:resultatsFacteurInfluenceSurLeComportement}


Della Croce et Scatamacchia ne comparent les algorithmes que sur 2 familles de distributions : 
uniforme et non-uniforme. Distributions générées avec 3 paramètres différents, le résultat est synthétisé avec des instances de 5, 10, 25 machines, et 10, 50, 100, 500, 1000 jobs. 
Les différences trouvées entre notre expérience et celle de Della Croce et Scatamacchia peuvent 
être dues à une variété trop grande de paramètres résumés en un seul résultat.

\bigskip
\paragraph{Influence de la distribution}
Pour vérifier si la distribution statistique utilisée pour générer les listes de temps 
  a une influence sur le résultat 
  nous reprenons la même expérience avec 2 autres familles de distributions : 
  Gamma et beta de paramètres $\alpha = 1$ et $\beta = 1$,
  sur des instances de 5, 10, 50, 100, 500, 1000 jobs, 
  à ordonnancer sur 5, 10, 25 machines,
  sur 10 campagnes.

Le résultat est donné figure \ref{fig:resultatReproduction10GammaBeta}.
SLACK descend à 68.7\% contre LPT, 
n'est plus qu'à 43,4\% contre COMBINE et
à 13.5\% contre LDM

\bigskip
Le type d'instance a donc une influence sur le comportement des algorithmes, notamment sur l'efficacité de SLACK.
   
%--------------------------------------------------------
% Figure resultat obtenu par 10 cmpagnes type DCS mais en Gamma/Beta
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{5_Resultat_Reproduction10GammaBeta.pdf}
\caption{Résultat obtenu avec 10 campagnes de tests avec des distributions Gamma et Beta.}
\label{fig:resultatReproduction10GammaBeta}
\par}
\end{figure}

\bigskip
\paragraph{Influence du nombre de jobs}
Les résultats précédents sont calculés et cumulés avec des instances de 100, 1000 et 10000 jobs. 
Peut-être que SLACK est meilleurs pour des instances de 100 jobs et cacherait, avec le cumul des résultats, 
  des difficultés pour des instances de 1000 jobs. 
Pour vérifier si le nombre de jobs a une incidence sur le comportement des heuristiques, 
  nous reprenons la même expérience avec 
  les 2 familles de distributions gamma et beta de paramètres $\alpha = 1$ et $\beta = 1$,
  des instances uniquement de 1000 jobs à ordonnancer sur 5, 10 et 25 machines,
  sur 10 campagnes.
%\lp{Dire pourquoi tu fais ça}
%--------------------------------------------------------
% Figure resultat obtenu par 10 cmpagnes type DCS mais en Gamma/Beta et 1000 jobs
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{6_Resultat_Reproduction10GammaBeta1000.pdf}
\caption{Résultat obtenu avec 10 campagnes de tests avec des distributions Gamma et Beta sur des instances de 1000 jobs.}
\label{fig:resultatReproduction10GammaBeta1000}
\par}
\end{figure}

Le résultat en figure \ref{fig:resultatReproduction10GammaBeta1000} indique que 
  SLACK ne domine plus LPT avec 48\% de ``WIN'' et
  laisse l'efficacité à COMBINE et LDM avec respectivement 22,5\% et 26,1\%.



\bigskip
\paragraph{Influence du cumul des résultats}
Les campagne précédentes cumulaient des données hétérogènes (nombre de jobs, distributions). 
Pour vérifier si un cumul de paramètres différents peut masquer dans le résultat un comportement par paramètre, nous retirons la loi de distribution beta dans la génération des listes de temps.
Donc 1 familles de distributions gamma de paramètres $\alpha = 1$ et $\beta = 1$, 
  des instances uniquement de 1000 jobs à ordonnancer sur 5, 10 et 25 machines,
  sur 10 campagnes.
%\lp{Dire pourquoi tu fais ça}
%--------------------------------------------------------
% Figure resultat obtenu par 10 cmpagnes type DCS mais en Gamma et 1000 jobs
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{7_Resultat_Reproduction10Gamma1000.pdf}
\caption{Résultat obtenu avec 10 campagnes de tests avec une distribution Gamma sur des instances de 1000 jobs.}
\label{fig:resultatReproduction10Gamma1000}
\par}
\end{figure}

SLACK n'est plus qu'à 25\% contre LPT, 15\% contre COMBINE et 17\% contre LDM (figure \ref{fig:resultatReproduction10Gamma1000}).
Une tentative d'explication de l'efficacité de SLACK par distribution est faite en \ref{ssec:resultatsSLACKNonUniforme}. 

Donc un cumul de paramètres différents masque le comportement des heuristiques par paramètres. 

%\jb{Il manque une tentative d'explication sur pourquoi SLACK est moins bon sur des distributions %gamma ou beta}

\subsection{Cartographie des heuristiques}
\label{ssec:resultatsCartographie}

Della Croce et Scatamacchia utilisent des instances de 10, 50, 100, 500 et 1000 jobs à ordonnancer sur 5, 10 et 25 machines. 
Ce qui représente 13 points de tests 
  (les instances 
  $\{10~jobs,10~machines\}$ et 
  $\{10~jobs,25~machines\}$ n'existent pas car $m\geq n$).
En faisant évoluer $n$ de 10 à 1000 et $m$ de 5 à 50, 
  et en consignant l'algorithme (entre LPT et SLACK) qui donne 
  le makespan relatif le plus bas, nous obtenons le graphe en figure \ref{fig:resultatComparaisonLPTSLACK}.
Les points rouges représentent les 13 points de test en question.

Les zones jaunes (algorithmes sont équivalents) correspondent à la partie ``optimale'', 
  où les heuristiques calculent un makespan égal à l'optimal. Cette partie se situe entre une demi-droite $n=m$ et une demi-droite $n = 2m-1$.   

%--------------------------------------------------------
% Figure resultat comparaison de LPT et SLACK sur n et m
%--------------------------------------------------------
\begin{figure}
\centering
\includegraphics[width=\columnwidth]{8_comparaison_LPT_SLACK_2D.png}
\caption{comparaison LPT et SLACK sur 3 distributions avec $10\leq n \leq 1000$ et $5\leq m \leq 50$}
\label{fig:resultatComparaisonLPTSLACK}
\end{figure}

%\lp{Parler de la partie jaune optimale ? D'ailleurs on peut signaler
%  qu'il n'y a pas de jaune..}

En distribution uniforme SLACK domine largement avec 
  un petit nombre de machines. Mais en montant en $m$ LPT devient un peu 
  plus présent.
En distribution non-uniforme SLACK est vraiment plus efficace que
%LPT.\lp{Tu as une idée de la raison ?}
Par contre, en distribution gamma LPT devient vraiment plus efficace.

Il est à remarquer que les points rouges du protocole expérimental de 
  Della Croce et Scatamacchia sont placés principalement à des coordonnées
  où SLACK domine (dans les instances à distribution uniforme et non-uniforme).

%--------------------------------------------------------
% Figure resultat comparaison de tous les algorithmes 
%--------------------------------------------------------
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{9_resultatComparaisonAlgoDistributions.jpeg}
\caption{comparaison LPT SLACK COMBINE et LDM par algorithme et par distribution avec 
  $10\leq n \leq 1000$ et $5\leq m \leq 50$}
\label{fig:resultatComparaisonAlgoDistributions}
\par}
\end{figure}

La figure \ref{fig:resultatComparaisonAlgoDistributions} donne la photographie d'une infime partie 
  du comportement de chaque algorithme par famille de distribution 
  (gamma, non-uniforme et uniforme) 
  pour des instances, dont le nombre de machines est compris entre 5 et 50 
  et le nombre de jobs varie de 10 à 1000. 

Il est à noter plusieurs phénomènes remarquables :
\begin{itemize}
	\item En distribution gamma les algorithmes se stabilisent 
	assez rapidement plus le nombre de jobs $n$ est élevé.
	
	Le makespan relatif dessine une bande oblique de ``pires cas'' 
	qui suit la ligne $n = 2m$ pour rapidement converger vers 1 
	lorsque $n$ augmente. 
	Cette bande est de plus en plus épaisse avec un nombre 
	élevé $m$ de machines;
	 
	\item En distribution uniforme SLACK converge moins rapidement que 
	LPT et LDM. Mais de façon générale plus le nombre de machines $m$ 
	est élevé et plus la convergence vers 1 du makespan relatif nécessite 
	un nombre élevé $n$ de jobs.
	
	Le makespan relatif dessine des vagues obliques de ``pires cas'' 
	qui débutent suivant la ligne $n = 2m$ pour s'estomper petit à petit 
	et converger vers 1 lorsque $n$ augmente. 
	Ces vagues sont de plus en plus larges avec un nombre 
	élevé $m$ de machines et selon l'algorithme;
	
	\item En distribution non-uniforme tous les algorithmes ont du mal 
	à converger vers un makespan relatif à 1. Les 4 heuristiques sont à 
	peu près équivalentes en valeurs et SLACK est plus efficace par 
	rapport à LPT de très peu.
	
	Le makespan relatif dessine des formes de ``pires cas'' qui font penser 
	à des interférences;
	
	\item les 13 points rouges ne sont pas forcément placés à des 
	coordonnées stratégiques qui nous permettraient une comparaison 
	plus catégorique. 
\end{itemize}

\subsection{SLACK et la famille NON-UNIFORME}
\label{ssec:resultatsSLACKNonUniforme}

Pourquoi SLACK est très efficace dans une instance dont les temps sont générés à l'aide de la
  règle NON-UNIFORME ? 
  
La stratégie gloutonne de SLACK consiste à 
  trier les temps dans le sens décroissant,
  créer des tuples de m jobs de cet ensemble trié 
  et trier ensuite chaque tuple par ordre décroissant de la différence 
  entre le premier et le dernier élément de chaque tuple (slack).

En reformulant la stratégie, SLACK crée des paquets de $m$ jobs qui vont s'empiler exactement un à un 
  sur les $m$ processeurs. 
Le premier paquet (tuple) présente une importante différence entre le premier et le dernier job, 
  ce qui peut faire penser à un trapèze rectangle dont le sommet du haut est fortement penché. 
Le deuxième paquet dont la différence des deux jobs d'extrémités est un peu moins importante 
  va un peu compenser celle du premier paquet, pour former un trapèze rectangle dont le sommet 
  est moins penché. 
Et ainsi de suite jusqu'à avoir empilé tous les tuples, et rendre le sommet du haut du trapèze rectangle le plus horizontal possible. Et à chaque itération, chaque élément de chaque tuple a été également répartis sur chacun des processeurs.

%--------------------------------------------------------
% EXEMPLE SLACK IDEAL
%--------------------------------------------------------
\begin{example}
Déroulement de SLACK dans un environnement idéal.

% FIGURE des tuples
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{Slack_Non_Unif_Exemple_Ok1.png}
\caption{Préparation des tuples pour SLACK avec $10\leq n \leq 1000$ et $5\leq m \leq 50$}
\label{ex:SLACKOK1}
\par}
\end{figure}

% FIGURE affectation des tuples
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{Slack_Non_Unif_Exemple_Ok2.png}
\caption{Ordonnancement des tâches par tuple avec $10\leq n \leq 1000$ et $5\leq m \leq 50$}
\label{ex:SLACKOK2}
\par}
\end{figure}

Soit la liste de temps déjà ordonnée $$P = \{89, 84, 55, 51, 51, 49, 47, 15, 10, 9, 7, 4\}$$ à ordonnancer sur 3 machines. Ce qui donne les tuples ordonnés suivants (figure \ref{ex:SLACKOK1}):
\begin{itemize}
	\item $T_1$ $=\{47, 15, 10\}$, slack = 37;
	\item $T_2$ $=\{89, 84, 55\}$, slack = 34;
	\item $T_3$ $=\{9, 7, 4\}$, slack = 5;
	\item $T_4$ $=\{51, 51, 49\}$, slack = 2.
\end{itemize}
% \jb{Ça ne correspond pas à la figure}

Pour chaque tuple, chaque tâche est affectée à chaque processeur (figure \ref{ex:SLACKOK2}), ce qui abouti vers une répartition équilibrée de temps par machine. Le makespan est égale à l'optimal

\end{example}

Par contre si un job a un temps qui déstabilise cette stratégie, comme par exemple le premier job du deuxième tuple qui a un temps inférieur au slack du premier tuple, celui-ci provoque un déséquilibre a chaque itération
qui fini par un décalage entre makespan et optimal.     
%\jb{Manque des verbes dans les phrases précédentes}

Plus formellement si dans 
$$P = \{p_1, \ldots, p_m\}, \{p_{m+1}, \ldots, p_{2m}\}, \ldots, \{p_{n-m}, \ldots p_n\}$$
nous avons $p_{m+1} < p_m - p_1$, à l’opération du deuxième tuple, 2 jobs seront affectés au même processeur. Ce qui aura comme effet de déstabiliser l'harmonie des affectations des jobs de chaque tuple à chaque processeur et de provoquer un décalage entre l'optimal et le makespan.


%--------------------------------------------------------
% EXEMPLE SLACK NON IDEAL
%--------------------------------------------------------
\begin{example}
Déroulement de SLACK dans un environnement non idéal.

% FIGURE des tuples
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{Slack_Non_Unif_Exemple_PasOk1.png}
\caption{préparation des tuples pour SLACK avec $10\leq n \leq 1000$ et $5\leq m \leq 50$}
\label{ex:SLACKPasOK1}
\par}
\end{figure}

% FIGURE affectation des tuples
\begin{figure}
{\centering
\includegraphics[width=\columnwidth]{Slack_Non_Unif_Exemple_PasOk2.png}
\caption{Ordonnancement des tâches par tuple avec $10\leq n \leq 1000$ et $5\leq m \leq 50$}
\label{ex:SLACKPasOK2}
\par}
\end{figure}

 
Soit la liste de temps déjà ordonnée $$P = \{90, 75, 53, 42, 38, 38, 36, 24, 22, 13, 11, 8\}$$ à ordonnancer sur 3 machines. Ce qui donne les tuples oordonnés suivants
\begin{itemize}
	\item $T_1$ $=\{90, 75, 53\}$, slack = 37;
	\item $T_2$ $=\{36, 24, 22\}$, slack = 14;
	\item $T_3$ $=\{13, 11, 8\}$, slack = 5;
	\item $T_4$ $=\{42, 38, 38\}$, slack = 4.
\end{itemize}
(figure \ref{ex:SLACKPasOK1}
Le premier job de $p_{1 \in T2}=36 < slack(T_1)=37$ %\lp{PB notation du job ?}
Après l'affectation de $T_1$ nous avons la répartition des charges des 
 processeurs suivante $\{(90), (75), (53)\}$.
Puis vient l'affectation de $T_2$, avec en premier le job $p_{T_2 1}=36$
nous avons la répartition des charges des processeurs suivante $\{(90), (75), (89 : 53,36)\}$. Le troisième processeur vient d'être chargé mais son poids $(89)$ est toujours inférieur au premier processeur $(90)$. Ce qu'aucun job de ce tuple ne sera affecté au premier processeur cette fois-ci (figure \ref{ex:SLACKPasOK2}).

Cette perturbation va se propager jusqu’à la fin de l'algorithme. Le makespan trouvé sera différent de l'optimal. 
\end{example}

Dans une liste de temps de type non-uniforme de paramètres [a, b] le slack maximum possible 
  est égal à $slack_{max} = 0.9(b-a)$. 
Pour perturber le fonctionnement de SLACK il faudrait une valeur de temps inférieure à $slack_{max}$. 
Or, contrairement à gamma, beta, uniforme, voire reel avec PWA, 
  une liste de temps non-uniforme ne contient aucune valeur comprise entre $0.9(b-a)$ et $0.2(b-a)$ 
  et seulement $2\%$ des éléments de la liste sont inférieurs à $0.2(b-a)$.
Ce qui réduit presque à $0$ les possibilités de générer une valeur qui peut potentiellement perturber SLACK.

Tester SLACK dans une instance de type non-uniforme oriente le résultat d'efficacité.
Les listes réelles ne peuvent pas être non uniforme comme défini dans \cite{frangioni2004multi} 
  car il y aura toujours une valeur entre les bornes $0.9(b-a)$ et $0.2(b-a)$ pour invalider 
  l'appartenance d'une archive de tâches réelles à une règle non uniforme.         
%\lp{La question qui se pose est: est-ce que les instances réelles sont
%NON-UNIFORMES ?}


\section{Discussion} \label{sec:discussion}

SLACK est plus efficace que LPT suivant 13 points de tests dans un protocole expérimental. 
Mais il suffit de sortir de ce périmètre pour obtenir une conclusion différente. 
Della Croce et Scatamacchia ont utilisé et combiné des variables 
  soit, trop différentes pour sortir un schéma de causalité pertinent, 
  soit pas assez représentatives pour en déduire un comportement général.  
En effet, certains points où SLACK est très efficace ont masqués 
  d'autres résultats où SLACK est moins percutant.
Aussi, certains points représentent des instances où tous les algorithmes convergent sur l'optimal 
ce qui réduit encore le nombre de points de tests. 
L'expérience est donc conditionnée par quelques points. 
Nous nous retrouvons devant un échantillon de tests biaisé et ne pouvons pas affirmer, 
  même sur une distribution non-uniforme, 
  que SLACK améliore LPT. 

Au delà de ce problème se pose la question : comment tester une heuristique par rapport à d'autres heuristiques par l'expérimentation ?
D'un point de vue théorique ces heuristiques ont un ratio d'approximation, 
  une complexité en temps, voire un comportement asymptotique. 
Mais le ratio d’approximation n’est qu'une indication prouvée existante 
  à un instant donné et prévaut tant qu'un nouveau ratio d'approximation 
  plus proche de l'optimal n'est pas trouvé et/ou prouvé. 
Même si entre 2 heuristiques dont l'une à un ratio d'approximation 
  supérieur à l'autre, cette heuristique supposée théoriquement moins 
  efficace peut obtenir de meilleurs résultats par l'expérience.      
Le principe de randomisation est essentiel pour créer des échantillons servant 
  de support expérimental. 
Or un algorithme comparé à d'autres, qui présente de meilleurs résultats 
  sur une distribution supposée perturber le comportement de toute heuristique 
  ne peut pas être gratifié d'algorithme améliorant un autre algorithme 
  car il peut devenir mauvais sur une autre distribution. 
Pour tester une heuristique et en extraire une conclusion catégorique, 
  il faudrait la tester sur toutes distributions et combinaisons 
  de distributions en faisant évoluer les paramètres de chacune d'elles 
 ($a$ et $b$ pour uniforme et non-uniforme, $\alpha$ et $\beta$ 
  pour les distributions gamma et beta $\ldots$), 
  et par rapport à une large variation de $n$ et $m$.  
Ce qui constitue un problème combinatoire.

Pour finir, les temps des jobs soumis aux processeurs sont des séquences dont la répartition ressemble à des 
  lois statistiques déduites d'observations de phénomènes ou d'activités naturels. 
Or la règle non-uniforme n'est pas inspirée des hasards naturels. 
Les lois gamma, beta, exponentielles ont beaucoup plus de chance de représenter un échantillon de jobs
  contrairement à la règle non-uniforme. 

\section{Conclusion} \label{sec:conclusion}

Nous venons de reproduire à l'identique le protocole expérimental de \dcs qui compare les heuristiques LPT, LDM, COMBINE et SLACK sur les 2 distributions uniformes et non-uniformes. 
Ce protocole n'est pas reproductible car nous ne trouvons pas tout à fait les mêmes résultats. 
Estimant ce protocole peut-être restreint, nous élargissons les paramètres expérimentaux 
  à d'autres valeurs de $n$ et $m$ et 
  à d'autres distributions statistiques telles que beta, gamma et exponentielle.
Les résultats obtenus montrent que SLACK n'améliore pas de façon significative LPT 
  contrairement à la conclusion de \dcs. 
Le protocole expérimental des auteurs n'est pas assez large pour avoir une bonne idée 
  du comportement de leur stratégie gloutonne par rapport aux autres algorithmes.  
    
L'expérience n'est pas reproductible car l'échantillon comporte un biais. Les points utilisés pour tester les
  heuristiques ne sont pas assez nombreux.
SLACK parait plus efficace dans une règle non-uniforme mais cela est dû à la construction de 
  l'heuristique elle-même. 
\dcs ont sélectionné des instances non-uniformes car cette règle de génération de nombres est supposée 
  perturber LPT. Mais cette règle n'est pas universelle et ne représente pas les autres lois statistiques 
  qui ont plus de chance d'être représentées dans une instance réelle et où les algorithme se 
  comportent différemment.

Comparer des heuristiques par l'expérimentation est une tâche difficile tant les possibilités sont nombreuses. 
Les bornes d'approximations ne donnent qu'une indication de pire cas. 
L'étude des surfaces asymptotiques dépendantes de $n$ et $m$ de ces algorithmes serait beaucoup plus intéressante.
car plus que le ratio d'approximation ces surfaces bornent la morphologie des heuristiques et peut-être
  indépendamment d'une loi de distribution.   

\begin{appendices}

\section*{génération des listes de temps avec Python}

Pour créer des listes de temps, nous utilisons la bibliothèque par défaut de génération de 
  nombres pseudo-aléatoires de Python, selon différentes règles statistiques. 

\bigskip
Les deux types de générations suivants implémentés génèrent des nombres entiers 
\footnote{\samepage La commande random.uniform(a,b) de Python renvoie un réel. La transformation en entier est effectuée à l'aide de la commande round(n).}.
Ce sont les deux seuls types de génération utilisés dans le protocole expérimental de comparaisons des heuristiques dans \cite{della2020longest}.
   
\begin{itemize}
\item Uniforme : les nombres pseudo-aléatoires générés, sont uniformément répartis 
  entre deux entiers $a$ et $b$.
   
  \begin{lstlisting}[language=Python]
	for i in range(n):
		rand = random.uniform(a,b)
  \end{lstlisting}

\item Non-uniforme. définie en tant que ``NON-UNIF'' dans \cite{frangioni2004multi}. Cette méthode produit
  une liste de temps de traitements dont 
  $98\%$ des éléments sont uniformément répartis dans l’intervalle  $[0.9 (b-a), b]$, et 
  le reste ($2\%$) est uniformément réparti dans l'intervalle  $[a, 0.2 (b-a)]$.


  \begin{lstlisting}[language=Python]
	n98 = int((98*n) / 100)
	    a1 = 0.9*(b-a)
    	b1 = b
    	a2 = a
    	b2 = 0.2*(b-a)
		...
    	for i in range(n98):
       		rand = random.uniform(a1,b1)

    	...
    
    	for i in range(n-n98):
    		rand = random.uniform(a2,b2)
  \end{lstlisting}
  
\end{itemize}

\bigskip
D'autres type de générations sont implémentées basés sur des lois statistiques (distribution). 
Celles-ci génèrent des nombres réels et acceptent des paramètres qui ont un effet sur 
  ``l'écrasement'' des courbes représentant les distributions et entrent dans le calculs 
  de la variance.

\begin{itemize}
\item Loi gamma : Accepte deux paramètres $k$ (``alpha'' dans l'implémentation) qui affecte la forme, et $\Theta$ (``beta'' dans l’implémentation) qui affecte l'échelle.  
  \begin{lstlisting}[language=Python]
	for i in range(n):
    		rand = random.gammavariate(alpha,beta)
  \end{lstlisting}
\item Loi exponentielle : Cas particulier de la loi gamma. Elle représente la durée de vie d'un événement. Elle accepte un paramètre $\lambda$ (lambda dans l'implémentation) qui affecte l'échelle.  
  \begin{lstlisting}[language=Python]
	for i in range(n):
    		rand = random.expovariate(lambd)
  \end{lstlisting}

\item Loi beta. Accepte deux paramètres de forme $\alpha$ qui affecte la forme, et $\beta$ (toujours à 1 dans notre cas) qui affecte aussi la forme.
  \begin{lstlisting}[language=Python]
	for i in range(n):
    		rand = random.betavariate(alpha,1)
  \end{lstlisting}

\end{itemize}

\section*{Algorithmes PTAS optimisés pour $\epsilon = \frac{1}{5}$ et $\epsilon = \frac{1}{6}$}
\label{ap:PTAS}

% Algorithme 1/5
% ---------------------
\begin{algorithm}[H]
\DontPrintSemicolon

Tant qu'il y a $1$ pièce $j$ avec $p_j \in [0,6, 1]$, emballer j avec
$L[1 - p_j]$, si cette pièce existe.
Emballer $j$ toute seule sinon.

\BlankLine % Petit espace
Tant qu'il y a $2$ pièces $i$, $j$ avec $p_i, p_j \in [0,5, 0.6[$,
emballer $i$ et $j$ ensembles.

\BlankLine % Petit espace
\tcp{Chaque pièce restante a une taille inférieure à 0.5}
Tant qu'il existe $3$ pièces, dont la plus grande fait au moins 0.4,
trouver $L[0.3,0.4,0.5]$ et les pacquer ensembles.

\BlankLine % Petit espace
Tant qu'il existe des pièces dont la taille est dans [0.4,0.5[, pacquer
les $2$ plus grandes ensembles.

\BlankLine % Petit espace
\tcp{Chaque pièce restante a une taille inférieure à 0.4}
Prendre la plus petite pièce des pièces restantes. Si $p_j > 0.25$,
alors pacquer le reste des pièces en 3-bin.
Sinon, $p_j = 0.25 - \delta$ pour $\delta \geq 0$.
Si $3$ autres pièces existent, pacquer $j$
 avec $L[0.25, \frac{+\delta}{3}, 0.25 + \delta, 0.25 + 3 \cdot \delta]$.
Sinon, pacquer le reste dans 3-bin.


\caption{PTAS $\frac{1}{5}$-dual}
\label{algo:PTASDual1_5}
\end{algorithm}

\bigskip

% Algorithme 1/6
% ---------------------
\begin{algorithm}[H]
\DontPrintSemicolon

Tant qu'il existe une pièce $j$, telle que $p_j \in (\frac{2}{3},1)$,
emballer $p_j$ avec $L[1-p_j]$.

\BlankLine % Petit espace
Estimer le nombre total de 1-bin ou 2-bin d'une solution optimale du
reste de l'instance.
Pour chacun de ces bacs, l'emballer avec $L[\frac{1}{2}, \frac{2}{3}]$
si de telles pièces existent, sinon, l'emballer avec $L[\frac{2}{3}]$.

\BlankLine % Petit espace
\tcp{Pour le reste de la procédure, seuls les bacs qui ont }
\tcp{au moins $3$ pièces sont considérés.}

\BlankLine % Petit espace
\tcp{Chaque pièce restante a une taille inférieure à $\frac{2}{3}$}
Pour chaque pièce $j$ restante, avec une taille $\frac{1}{2}+\delta;
\delta \geq 0$, emballer $j$ avec $L[\frac{1}{4}-\frac{\delta}{2},
\frac{1}{3}-\delta]$.

\BlankLine % Petit espace
\tcp{Chaque pièce restante a une taille inférieure à $\frac{1}{2}$}
Estimer le nombre de 4-bin qui contient une pièce dont la taille est
dans l'intervalle $[\frac{5}{12}, \frac{1}{2}[$ dans un packing
optimal. Pacquer chaque bac avec $L[ \frac{7}{36}, \frac{5}{24},
\frac{1}{4}, \frac{1}{2}]$.

Pour chaque pièce restante de taille
$\frac{5}{12}+\delta, \delta \geq 0$, l'emballer dans un 3-bin avec
$L[\frac{7}{24}-\frac{\delta}{2}, \frac{5}{12}-\delta]$.

\BlankLine % Petit espace
\tcp{Chaque pièce restante a une taille inférieure à $\frac{5}{12}$}
Estimer le nombre de 3-bin d'une solution optimale pour le reste de
l'instance. Pour chacun d'eux, le pacquer avec $L[\frac{1}{3},
\frac{5}{12}, \frac{5}{12}]$.

\BlankLine % Petit espace
\tcp{Pour le reste de la procédure, seuls les bacs qui ont }
\tcp{au moins $4$ pièces sont considérés.}

Pour chaque pièce $j$ de taille $\frac{1}{3}+\delta, \delta \geq 0$,
emballer $i$
avec $L[\frac{2}{9}-\frac{\delta}{3},
        \frac{1}{4}-\frac{\delta}{2},
        \frac{1}{3}-\delta]$.

\BlankLine % Petit espace
\tcp{Chaque pièce restante a une taille inférieure à $\frac{1}{3}$}
Estimer le nombre de 5-bin qui contienne une pièce
dont la taille est comprise dans l'intervalle
$[\frac{7}{24},\frac{1}{3}[$ d'une solution optimale.
Emballer de tels bacs avec
$L[\frac{17}{96},
   \frac{13}{72},
   \frac{9}{48},
   \frac{5}{24},
   \frac{1}{3}]$.

Tant qu'il existe des pièces dont la taille est supérieure à $\frac{7}{24}$
Prendre la plus grande pièce de taille $p_j = \frac{7}{24}+\delta, \delta \geq 0$.
Pacquer i avec
$L[\frac{17}{72}-\frac{\delta}{3},
   \frac{13}{48}-\frac{\delta}{2},
   \frac{7}{24}+\delta]$.

Considérer la plus petite pièce $j$.
Si $p_j>\frac{1}{5}$, emballer les pièces restantes à raison de $4$ pièces par bac.
Si $p_j=\frac{1}{5}-\delta, \delta \geq 0$, pacquer $j$ avec
$L[\frac{1}{5}+\frac{\delta}{4},
   \frac{1}{5}+\frac{2 \cdot \delta}{3},
   \frac{1}{5}+\frac{3 \cdot \delta}{2},
   \frac{7}{24}]$.

\BlankLine % Petit espace



\caption{PTAS $\frac{1}{6}$-dual}
\label{algo:PTASDual1_6}
\end{algorithm}


\section*{Algorithme PA}
\label{ap:PA}

% Algorithme PA
% ---------------------
\begin{algorithm}[H]
\DontPrintSemicolon

Déterminer la borne inférieure $(LB)$ suivant l'algorithme de
McNaughton \cite{mcnaughton1959scheduling}.\;

Déterminer la borne supérieure $UB$ suivant l'heuristique LPT
(algorithme \ref{algo:LPT}).\;

\Si{$LB=UB$}{
  \Return la solution optimale est trouvée par l'heuristique LPT
}

\Repeter{Génération des d'inégalités impossible}
{
	Résoudre le programme de relaxation linéaire avec $C_{max} = LB$
	
	\Si {la relaxation est possible}
	{
	
		\Si {la solution obtenue est entière (donc faisable)}
		{
		\Return la solution obtenue qui est optimale
		}
		\Sinon
		{
		Générer des nouvelles inégalités 
		(inégalités et/ou inégalités transitoires) et les ajouter à la 
		nouvelle relaxation linéaire
		}
	}
	\Sinon
	{
	incrémenter $LB$ d'une unité
	}	


}
\Return Résoudre le problème avec un algorithme Branch\&Bound
.\;
\caption{PA\label{algo:PA}}
\end{algorithm}




\end{appendices} 



\bibliographystyle{plain}				% NE PAS ENLEVER !!!!!!!!!!
\bibliography{Bibliographie}			% Utilise Bibliographie.bib


% =======================================================
% ABSTRACT/RESUME
% =======================================================
\clearpage

%\abstractname{}


\selectlanguage{english}
\section*{Abstract} \label{sec:abstract}
%\paragraph{Abstract}
Consider the scheduling problem \problemGrahamP which consists in scheduling $n$ independent jobs 
  on $m$ identical machines in order to minimize the total processing time (makespan).
By revisiting the LPT rule heuristic, SLACK, an algorithm based on a greedy approach, was developed. 
To test the efficiency of SLACK, the authors compare it to the LPT rule, COMBINE and LDM heuristics by 
  subjecting them to uniform and non-uniform instances. 
The results show that SLACK significantly improves LPT.
We try to reproduce the experiment identically to validate the reproducibility. 
But we do not find the same results. 
To validate this bias we extend the experimental protocol to compare  
  other gamma, beta instances. 
With these new experimental parameters SLACK does not significantly improve LPT rule.
The comparison protocol of \dcs is not generalist, and the non-uniform instance is not sufficient to characterize the behavior of heuristics. 

Key words: Scheduling . Identical parallel machines . Heuristics . LPT rule . Empirical .     




\bigskip
\selectlanguage{french}
\section*{Résumé} \label{sec:resume}
%\paragraph{Résumé}
Considérons le problème d'ordonnancement \problemGrahamP qui consiste à planifier $n$ jobs indépendants 
  sur $m$ machines identiques dans le but de minimiser le temps total de traitement (makespan). 
\dcs ont développé, en revisitant l'heuristique LPT rule, SLACK un algorithme basé sur une stratégie gloutonne. 
Pour éprouver l'efficacité de SLACK, les auteurs le comparent aux heuristiques LPT rule, COMBINE et LDM en les soumettant à des instances uniformes et non-uniformes. 
D'après le résultat SLACK améliore de façon significative LPT.
Nous tentons de reproduire l'expérimentation à l'identique afin valider la reproductibilité. 
Mais nous ne trouvons pas les mêmes résultats. 
Pour valider ce biais nous élargissons le protocole expérimental de comparaisons  
  d'autres instances gamma, beta. 
Avec ces nouveau paramètres expérimentaux SLACK n'améliore pas de façon significative LPT rule.
Le protocole de comparaison de \dcs n'est pas généraliste, et l'instance non-uniforme ne suffit pas pour caractériser le comportement d'heuristiques. 

Mot clés : Ordonnancement . Machines parallèles identiques . Heuristiques . LPT rule . Empirique .     

\end{document}
