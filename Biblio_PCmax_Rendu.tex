% ######################################################################
%
% 			PREAMBULE
%
% ######################################################################

% -------------------------------------------------------
% Ce document est un raport. dizaine de pages / plusieurs sections
% -------------------------------------------------------
\documentclass[a4paper,12pt]{report}

% -------------------------------------------------------
% Utiliser latin1 pour les accents
% ne pas utiliser utf8 et  Latex n'aime pas utf8 ET latin1
%\usepackage[utf8]{inputenc}
% -------------------------------------------------------
\usepackage[latin1]{inputenc}

\usepackage[T1]{fontenc}
\usepackage[english,french]{babel}

% -------------------------------------------------------
% Trouvé dans un forum a voir plus tard 
% utile ou pas 
% significations
% -------------------------------------------------------
\usepackage{amsmath}
\usepackage{amssymb,amsfonts,textcomp}
\usepackage{color}
\usepackage{array}
\usepackage{supertabular}
\usepackage{hhline}
\usepackage{hyperref}
% \usepackage{unicode-math}	% pour prime dprime tprime 

% -------------------------------------------------------
% Théorèmes
% -------------------------------------------------------
\usepackage{amsthm}
\theoremstyle{plain}				% Choix du style 
\newtheorem{theoreme1}{Théorème}	% Définition de l'environnement 1 

\theoremstyle{definition}				% Choix du style
\newtheorem{definition1}{Definition} %[section]	% Définition de l'environnement définition
% -------------------------------------------------------
%pour utiliser
% \textsubscript{}
% {\textbar}
% -------------------------------------------------------
\usepackage{fixltx2e}

% -------------------------------------------------------
%BIBTEX
% -------------------------------------------------------
\usepackage{natbib}

%____________________________________________________________________
%
% Tout ceci ne fonctionne pas ! ou n'ai pas réussi à faire fonctionner
% \usepackage[backend=bibtex, style=numeric]{biblatex}	% Compilateur
% \bibliography{Bibliographie}			% Utilise Bibliographie.bib
% \addbibresource{Bibliographie.bib}
% \bibliographystyle{plain}
%____________________________________________________________________

% -------------------------------------------------------
% Pour les tableaux
% -------------------------------------------------------
%\usepackage{slashbox}
\usepackage{diagbox} % barre oblique pour les cellule à 2 entrées


% -------------------------------------------------------
% Pour les ALGORITHMES
% linesnumbered	: les lignes sont numérotées
% ruled			: Le caption est en haut et bordé de lignes horizontale 
% vlined		: Regroupement des bloc d'instructions par ligne verticales
% -------------------------------------------------------
\usepackage[linesnumbered, ruled, vlined]{algorithm2e} 
\SetKwProg{Init}{init}{}{}
% mettre les commentaire des algos en bleu
\usepackage{xcolor}
\newcommand\commentairesBleus[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{commentairesBleus}

% -------------------------------------------------------
% Information PDF généré
% -------------------------------------------------------
\hypersetup{pdftex, colorlinks=true, linkcolor=blue, citecolor=blue, filecolor=blue, urlcolor=blue, pdftitle=, pdfauthor=florianColas, pdfsubject=, pdfkeywords=}
\usepackage[pdftex]{graphicx}

% -------------------------------------------------------
% Information générales
% Utilisé par \maketitle 
% -------------------------------------------------------
\title{Historique des travaux autour du problème P{\textbar}{\textbar}Cmax}
\author{florian colas}
% \date{2020-05-01}
\date{\today}


% ######################################################################
%
% 			SOUVENT UTILISES
%
% ######################################################################
% Pm||Cmax 				: P\textsubscript{m}{\textbar}{\textbar}C\textsubscript{max}
% P2||Cmax 				: P\textsubscript{2}{\textbar}{\textbar}C\textsubscript{max}
% P||Cmax 				: P{\textbar}{\textbar}C\textsubscript{max}
%
% Appostrophes 			: {\textquoteright}
%
% en italique car latin : \textit{et al.}
%
% entourer un résultat
%	\begin{center}
%	\fbox{\begin{minipage}{\linewidth}
%	bla blabla
%	\end{minipage}}
%	\end{center}


% ######################################################################
%
% 				DOCUMENT
%
% ######################################################################

\begin{document}

% =======================================================
% Page de garde
% Utilise Information générales
% Ecrit le titre + auteur + date
% =======================================================
\maketitle

% -------------------------------------------------------
% Table des matières
%
% On renomme en Sommaire (document français)
%
% On définit la profondeur de la table des matières 
% -1 partie,    0 Chapitre, 
% 1 Section,    2 sous sections,  3 sous sous section
% 4 Paragraphe, 5 Sous paragraphe
%
% Les sections sont numérotées 1 2 3
% -------------------------------------------------------
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\contentsname}{Sommaire}
\setcounter{tocdepth}{2}	% pour la table des matières
\setcounter{secnumdepth}{3}	% pour les section sous et sous sous
\tableofcontents

% =======================================================
% 1 INTRODUCTION
% =======================================================
\section{Introduction}

texte


\section{Présentation du problème.}
texte 
\subsection{Parallélisme.}
Le parallélisme est un type d{\textquotesingle}architecture informatique
dans lequel plusieurs processeurs exécutent ou traitent une application
ou un calcul simultanément. IL aide à effectuer de grands calculs en
divisant la charge de travail entre plusieurs processeurs, qui
fonctionnent tous en même temps. 

Il existe quatre types de parallélismes, définis par la taxonomie de
Flynn\textsuperscript{(1)}. Cette classification est basée sur deux
notions : le flot d{\textquoteright}instructions (simple ou multiple),
et le flot de données (simple ou multiples) ; un algorithme est un flot
d{\textquoteright}instructions à exécuter sur un flot de données. 


% -------------------------------------------------------
% TABLEAU taxonomie de Flynn
% diagbox permet d'avoir une barre oblique pour les deux entrées
% \backslashbox{Instructions}{Donnée} & Simple & Multiple NE FONCTIONNE PAS
% on cadre à gauche le tableau pour avoir plus de place
% -------------------------------------------------------
\begin{flushleft}
\begin{tabular}{|p{3.6cm}|p{6cm}|p{6cm}|}

% --------------------------
% TITRES
% --------------------------
\hline
\diagbox[width=10em]{Instructions}{Données} & Simple & Multiple \\
\hline

% --------------------------
% LIGNE SIMPLE
% --------------------------
Simple 

%---------------------------
&
SISD

premiers PC

machine de Von Neumann

~

Obsolète, car tous les PC sont désormais multi-c{\oe}ur.
%---------------------------
&
SIMD

Machines synchrones

Pipeline

~

Exécution d{\textquoteright}une instruction unique sur des données différentes.
\\	\hline
% --------------------------
% LIGNE MULTIPLE
% --------------------------

Multiple

%---------------------------
&
MISD

Machines vectoriels

Tableau de processeurs

~

Exécute plusieurs instructions sur une même donnée. 
%---------------------------
&	
MIMD

Multi processeurs à mémoire distribuée.

Multi processeurs à mémoire partagée (multi-c{\oe}ur).

Multi Ordinateur.
%---------------------------
\\
\hline
\end{tabular}
Taxonomie de Flynn
\end{flushleft}


Les premières machines parallèles étaient des réseaux
d{\textquoteright}ordinateurs, et des machines vectorielles (faiblement
parallèles, très coûteuses), telles que l{\textquoteright}IBM 360, les
Cray1. La plupart des machines parallèles contemporaines sont désormais
MIMD.

On peut définir une machine parallèle comme un ensemble de processeurs
qui coopèrent et communiquent.

\bigskip

{\centering 
\includegraphics[width=8.334cm,height=4.034cm]{Biblio_PCmax_Rendu-img1.jpg}
\par}
{\centering 
IBM 360-91 (le plus rapide et le plus puissant en service en 1968) NASA.
Centre de vols de Greenbelt (Md)
\par}


\subsection{Ordonnancement.}
Sur une machine non parallèle, les tâches sont exécutées séquentiellement, les unes après les autres. Certaines tâches, ou jobs peuvent demander plus de temps que d{\textquoteright}autres pour être entièrement traitées. 
Lorsque plusieurs ressources (processeurs, machines, coeurs) sont disponibles, ou que des jobs a exécuter ne sont pas indépendants (même traités sur un seul processeur), se pose alors, un problème d{\textquoteright}ordonnancement. 
Celui-ci consiste à organiser, dans le temps, les jobs à exécuter, en les affectant à une ressource donnée, de manière à satisfaire un certain nombre de contraintes, tout en optimisant un ou des objectifs.
L{\textquoteright}ordonnancement, fait partie de la catégorie des problèmes d{\textquoteright}optimisation combinatoire. 

Les problèmes qui s{\textquoteright}y rattachent sont très variés. 
Premièrement, la nature des machines parallèles doit être considérée. Celles-ci peuvent être :
\begin{itemize}
\item identiques. (Le même temps de traitement sera nécessaire, d{\textquoteright}une machine à l{\textquoteright}autre) ; 
\item uniformes (un quotient de vitesse qi propre à une machine est à appliquer pour chaque tâche affectée  à cette machine pour déterminer le temps de traitement nécessaire) ; 
\item indépendantes (les temps de traitements des tâches sont ni uniformes ni proportionnels d{\textquoteright}une machine à l{\textquoteright}autre).
\end{itemize}
Ensuite, des contraintes peuvent affecter les jobs eux-mêmes. Dans le cas d{\textquoteright}un problème préemptif, les taches peuvent être interrompues, et reprises ultérieurement. Il est possible que les jobs soient indépendants, ou au contraire, être liées par des relations de précédence. Ces jobs ne sont disponibles qu{\textquoteright}à partir d{\textquoteright}une certaine date. Ou encore, être de durée égale, ou tous de durée différente.

Pour finir, l{\textquoteright}objectif de l{\textquoteright}ordonnancement est d{\textquoteright}optimiser un critère. Par exemple, minimiser la somme des dates de fin, la somme des retards, le nombre de tâches en retard, ou simplement, le retard total. Mais le plus habituel, est de chercher à minimiser le temps total de traitement de tous les jobs, i.e minimiser le makespan.


\subsection{Enoncé du P{\textbar}{\textbar}C \textsubscript{max}}

Ces diverses possibilités définissent divers problèmes
d{\textquoteright}ordonnancements différents, recensés et classifiés
\ par Graham et al. [1], qui introduit la notation trois-champs $\alpha
${\textbar}$\beta ${\textbar}$\gamma $ .

\bigskip

Le problème P\textsubscript{m}{\textbar}{\textbar}C\textsubscript{max} se définit alors ainsi :

\begin{itemize}

% -------------------------------------------------------
% ALPHA P Type de machines
% -------------------------------------------------------
\item $\alpha $ = $\alpha $1 $\alpha $2, détermine l{\textquoteright}environnement machines.
$\alpha $ = P : Les machines sont parallèles et identiques : Un job, une tâche prendra le même temps de traitement qu{\textquoteright}il soit exécuté sur une machine ou une autre. Le nombre de machines (m) est variable.

% -------------------------------------------------------
% BETA Contraintes
% -------------------------------------------------------
\item $\beta $ $\subset$ \{ $\beta $1, $\beta $2, $\beta $3, $\beta $4, $\beta $5, $\beta $6\}, détermine les caractéristiques des jobs, ou des tâches.
$\beta $ est vide. Ce qui signifie~que la préemption n{\textquoteright}est pas autorisée (les jobs doivent être exécutés d{\textquoteright}une traite, sans interruption ni coupure) \ et qu{\textquoteright}il n{\textquoteright}y a pas de relation entre les jobs (ils sont indépendants).

% -------------------------------------------------------
% GEMEL Optimisation
% -------------------------------------------------------
\item $\gamma $ détermine le critère à optimiser.
$\gamma $ = C\textsubscript{max} : on cherche à optimiser le makespan,
i.e le temps de traitement total.

\end{itemize}

\bigskip

\begin{definition1}{P\textsubscript{m}{\textbar}{\textbar}C\textsubscript{max}}

P\textsubscript{m}{\textbar}{\textbar}C\textsubscript{max} consiste à planifier un ensemble J~=~\{1,2,{\dots},n) de n jobs simultanés, pour être traités par m machines identiques et parallèles. Chaque job, qui requière une opération, peut être traité par une des m machines. Le temps de traitement de chaque job (P\textsubscript{i} avec i~${\in}$ N) est connu à l{\textquoteright}avance. Un job commencé, et complété sans interruption. Les jobs, indépendants, sont exécutés par une seule machine, et une machine ne peut traiter qu{\textquoteright}un seul job
à la fois.

\end{definition1}


\subsection{Problématique}

Comme l{\textquoteright}ont démontré Garey et Johnson, P\textsubscript{2}{\textbar}{\textbar}C\textsubscript{max} est un problème NP-Difficile \citep{garey1978strong}, et P{\textbar}{\textbar}C\textsubscript{max} est un problème NP-Difficile au sens fort \citep{garey1982computers}. Cependant, P~\textsubscript{m}{\textbar}{\textbar}C\textsubscript{max} devient un problème NP-Difficile, du moment que le nombre de machines est fixé \cite{chen1999potts}, comme l{\textquoteright}a montré Rothkopf \cite{rothkopf1966scheduling}, qui a présenté un algorithme de programmation dynamique.

Donner la solution optimale à un problème d{\textquoteright}ordonnancement (dans notre cas P~\textsubscript{m}{\textbar}{\textbar}C\textsubscript{max}) n{\textquoteright}est pas réaliste. Même pour un problème de taille modeste, la résolution de celui-ci demanderait un temps excessif et donc rédhibitoire. 

La résolution du problème d{\textquoteright}ordonnancement va reposer sur des méthodes d{\textquoteright}approche, qui consistent à calculer en temps polynomial, une solution «~assez~» proche de la valeur optimale.

Dans la littérature, l{\textquoteright}étude d{\textquoteright}ordonnancement est très riche et abondante. Le but étant d{\textquoteright}améliorer le temps de calcul, et d{\textquoteright}approcher le résultat optimal.

\section{Résoudre le problème}

Comme évoqué précédemment, l{\textquoteright}existence d{\textquoteright}une solution qui résout le problème n{\textquoteright}est pas pensable, à moins que P = NP.

\subsection{Notations utilisées}

Chaque document utilise sa propre notation, mais les notions sont les mêmes.
Soient les données du problème 

\begin{itemize}
% -------------------------------------------------------
% ENSEMBLE DES JOBS J
% -------------------------------------------------------
\item un ensemble de n jobs (ou tâches) $J = \{1, 2, ..., n\}$
Chaque job j a un temps de traitement connu $p\textsubscript{j} P = \{p\textsubscript{1}, p\textsubscript{2}, ..., p\textsubscript{n}\}$

% -------------------------------------------------------
% ENSEMBLE DES MACHINES M
% -------------------------------------------------------
\item m machines parallèles identiques $M\textsubscript{i}~avec~(i = 1, 2, ..., m)$

% -------------------------------------------------------
% RESULTAT DE L'ALGORITHME A
% -------------------------------------------------------
\item $C_j^A(J)$ Le résultat de l'ordonnancement d{\textquoteright}un ensemble J de jobs, sur m machines parallèles, identiques, obtenu par l{\textquoteright}algorithme A.

% -------------------------------------------------------
% RESULTAT OPTIMAL
% -------------------------------------------------------
\item $C_j^\star(J)$ Le makespan optimal, idéal.

% -------------------------------------------------------
% RATIO OBTENU/OPTIMAL
% -------------------------------------------------------
\item $\Gamma(A)=\dfrac{C_j^A(J)}{C_j^\star(J)}$ Le ratio d{\textquoteright}approximation atteint par l'algorithme A au pire cas.

\end{itemize}

\subsection{Heuristiques}

Les heuristiques présentent plusieurs avantages. Leur complexité est réduite, et obtiennent de bonne performances. Elles représentent la plus grande partie des recherches concernant le problème {\textquoteright}ordonnancement, même si leurs performances, au pire cas, ne sont pas garanties.
Sont abordées ici les heuristiques les plus présentes dans la littérature.


\subsubsection{Basé LS (List Scheduling)}
% {\textquoteright}

L{\textquoteright}idée d{\textquoteright}une LS est de stocker l{\textquoteright}ensemble des jobs dans celle-ci, les trier dans un ordre particulier, avant de les affecter à une machine selon des règles définies.


\begin{itemize}

\bigskip
% -------------------------------------------------------
% LPT Rule
% -------------------------------------------------------
\item \textbf{algorithme LPT rule Graham \textit{et al.}, 1969}

% Présentaion
% ---------------------
Graham propose \cite{graham1969bounds} \textit{\textbf{Longest Processing Time (LPT) rule}}. 

\bigskip 
% Algorithme
% ---------------------
\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{instance de P\textsubscript{m}{\textbar}{\textbar}C\textsubscript{max}, avec m machines, n jobs et leur temps d{\textquoteright}exécution}
%\Begin{ %inutile ici et rajoute un nuero de ligne

\BlankLine % Petit espace 
Trie les jobs de l{\textquoteright}ensemble J dans l{\textquoteright}ordre décroissant de leur temps d{\textquoteright}exécution et ré-indexe l{\textquoteright}ensemble de telle manière à obtenir : $p_1 \geq p_2 \geq ... \geq p_n$

\BlankLine % Petit espace 
Parcours la liste, et affecte chaque job à la machine la moins chargée, à ce moment là.
% }
\caption{LPT Rule\label{LPT}}
\end{algorithm}

\bigskip
% Exemple
% ---------------------
Exemple

Soit $P=\{13,10,7,6,6,5,3,2\}$, l{\textquoteright}ensemble des $p_j$ déjà triés dans l{\textquoteright}ordre décroissant à appliquer sur 4 machines parallèles identiques :

{\centering 
\includegraphics[width=8.334cm,height=4.034cm]{Biblio_PCmax_Rendu_exLPT1.jpg}
\par}
{\centering 
\par}
Nous obtenons $C_4^{lpt}(J)=14$

\bigskip

% Complexité
% -------------------------------------------------------
\begin{flushleft}
\begin{tabular}{|p{10cm}p{4cm}|}
% TITRES (pas de titre)
\hline 

% Ligne blanche
 & \\	

% Ligne Complexité
Le~tri~puis~l{\textquoteright}affectation~s{\textquoteright}effectuent~en & $O(n log n + n log m)$
\\	% pas de ligne \hline

% RATIO
Le~ratio~d{\textquoteright}approximation	&	$\Gamma(LPT)\leq \dfrac{4}{3} - \dfrac{1}{3m}$
\\ 

% Ligne blanche
& \\
\hline
\end{tabular}
%pas de legende
\end{flushleft}

\bigskip
% -------------------------------------------------------
% LPT-REV 
% -------------------------------------------------------

\item \textbf{algorithme LPT-REV (Croce \textit{et al.}, 2018)}


% Présentaion
% ---------------------
Le ratio d{\textquoteright}approximation obtenu par LPT (\ref{LPT}) $(\Gamma(LPT)\leq \dfrac{4}{3} - \dfrac{1}{3m})$ est une borne supérieure que cet algorithme peut atteindre, mais qu{\textquoteright}il ne dépassera jamais. Chaque utilisation de LPT produira un résultat dont le ratio $\Gamma$ oscillera entre 1 et $\dfrac{4}{3} - \dfrac{1}{3m})$.

\bigskip
% Exemple pour l'explication
% ---------------------
Exemple de pire cas

Soit $P=\{7,7,6,6,5,5,4,4,4\}$, l{\textquoteright}ensemble des $p_j$ déjà triés dans l{\textquoteright}ordre décroissant à appliquer sur 4 machines parallèles identiques :

\bigskip

% partie insécable
\begin{minipage}{\linewidth}

\begin{flushleft}
LPT donne le résultat suivant
\end{flushleft}
{\centering 
\includegraphics[width=8.334cm,height=4.034cm]{Biblio_PCmax_Rendu_exLPT_Rev1.jpg}
\par}

\begin{flushleft}
$C_4^{lpt}(J)=15$
\end{flushleft}

\end{minipage}

\bigskip

% partie insécable
\begin{minipage}{\linewidth}

\begin{flushleft}
Un ordonnancement optimal aurait été :
\end{flushleft}

{\centering 
\includegraphics[width=8.334cm,height=4.034cm]{Biblio_PCmax_Rendu_exLPT_Rev2.jpg}
\par}


\begin{flushleft}
$C_4^{\star}(J)=12$
\end{flushleft}

\end{minipage}

Soit une marge d{\textquoteright} de $\dfrac{15}{12}$

Le ratio d{\textquoteright}approximation prévu pour $m=4$
$\dfrac{4}{3} - \dfrac{1}{3m}=\dfrac{16}{12} - \dfrac{1}{12}=\dfrac{15}{12}$

Ce cas, représente donc un pire cas pour LPT.

Croce \textit{et al.} \cite{della2018longest}, en examinant le comportement de LPT rule, notamment au niveau du ratio d{\textquoteright}approximation, constatent qu'icelui peut être réduit selon certaines configurations, ou instances du problème, et rédigent le théorème suivant :

\bigskip

\begin{theoreme1}

LPT a un rapport d{\textquoteright}approximation non supérieur à $\dfrac{4}{3} - \dfrac{1}{3(m-1)}$ pour $m \geq 3$ et $n \neq 2m+1$. 

LPT atteint la limite de Graham $\dfrac{4}{3} - \dfrac{1}{3m}$ pour $m \geq 2$ et uniquement dans le cas où $n=2m+1$, et la machine critique traite 3 jobs, tandis que les autres en traitent 2.

La machine critique est la machine qui exécute le job critique.

Le job critique (noté $J^\prime$) est le job qui détermine le makespan.
\end{theoreme1}

\bigskip

Le rapport d{\textquoteright} $\dfrac{4}{3} - \dfrac{1}{3(m-1)}$ est inférieur au ration $\dfrac{4}{3} - \dfrac{1}{3m}$ (quel que soit le nombre de machines)

\bigskip

NB

L{\textquoteright}exemple précédant (pire cas) a les caractéristiques suivantes :
\begin{itemize}
	\item nombre de job $n=2m+1$.
	\item la machine critique exécute 3 jobs.
	\item les autres exécutent 2 jobs.
	\item un rapport d{\textquoteright}approximation de $\dfrac{4}{3} - \dfrac{1}{3m}$
\end{itemize}

\bigskip 

Une modification à l'algorithme LPT rule est apportée afin de placer le problème P\textsubscript{m}{\textbar}{\textbar}C\textsubscript{max} toujours dans une instance où le ratio d{\textquoteright}approximation est $\leq \dfrac{4}{3} - \dfrac{1}{3(m-1)}$. Cette modification consiste à planifier en premier, le job critique sur une machine M1.

\bigskip

% Algorithme
% ---------------------
\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{instance de P\textsubscript{m}{\textbar}{\textbar}C\textsubscript{max}, avec m machines, n jobs}
%\Begin{ %inutile ici et rajoute un nuero de ligne

Apply LPT yielding a schedule with makespan $z_1$ and $k-1$ jobs on the critical macine before job $J^\prime$
\BlankLine % Petit espace 
Apply $LPT^\prime = LPT(J^\prime)$ with solution value $z_2$

\BlankLine % Petit espace 
\textbf{If}  $m=2$ \textbf{then} apply $LPT''=LPT([(J^\prime - k + 1), ... , J^\prime])$ with solution value $z_3$ and \textbf{return} $min[z_1,z_2,z_3]$

\BlankLine % Petit espace 
\textbf{Else} \textbf{return} $min(z_1,z_2)$

\caption{LPT-Rev\label{LPTRev}}
\end{algorithm}


\bigskip

% Complexité
% -------------------------------------------------------
\begin{flushleft}
\begin{tabular}{|p{10cm}p{4cm}|}
% TITRES (pas de titre)
\hline 

% Ligne blanche
 & \\	


% RATIO
Le~ratio~d{\textquoteright}approximation	&	$\Gamma(LPT-REV)\leq \dfrac{4}{3} - \dfrac{1}{3(m-1)}$
\\ 

% Ligne blanche
& \\
\hline
\end{tabular}
%pas de legende
\end{flushleft}


\end{itemize}


\subsubsection{Basé Bin-Packing}
Le problème Bin-packing, est semblable au problème P\textsubscript{m}{\textbar}{\textbar}C\textsubscript{max}. Il consiste à ranger des objets de taille différentes, dans des bacs identiques, tout en minimisant leur nombre.

L{\textquoteright}ensemble des n jobs $J~=~\{1, 2, ..., n\}$, et de leurs temps de traitement  $p_j~ P~=~\{p_1, p_2, ..., p_n\}$, peuvent être vus respectivement comme :
\begin{itemize}
\item un ensemble d{\textquoteright}objets $T~=~\{T_1, T_2, ..., T_n\}$
\item leur taille $L(T_i)$
\end{itemize}
Une taille maximale $C$ des bacs (ou boites) est donnée.
\bigskip

\begin{definition1}{Packing}

Un packing, est une partition $P<P_1, P_2, ..., P_m>$ tel que $L(P_j)~\leq~C$ avec $1 \leq j\leq m$. Le but est de placer les objets $T_i$ dans des bacs $P_j$ de taille $C$, de manière à minimiser le nombre de bacs $m$.
\end{definition1}

L{\textquoteright}idée est d{\textquoteright}utiliser le problème Bin-Packing à l'envers, pour approcher une solution au problème d{\textquoteright}ordonnancement.



\begin{itemize}

\bigskip
% -------------------------------------------------------
% MULTIFIT
% -------------------------------------------------------
\item \textbf{algorithme MULTIFIT}


% Présentaion
% ---------------------
Coffman \textit{et al.}, \cite{coffman1978application} se sont intéressés à l{\textquoteright}algorithme FFD (First Fit Decreasing), un outil de résolution du problème de Bin-Packing, pour l'adapter au problème P{\textbar}{\textbar}C\textsubscript{max}.
$FFD(T,C)$ renvoie le nombre de bacs de taille C non vides nécessaires, et l{\textquoteright}arrangement correspondant de l{\textquoteright}ensemble T d{\textquoteright}objets.

\bigskip
% Principe de l'algorithme
% ---------------------
Soit $T_m^\star~=~min\{C:FFD(T,C) \leq m\}$ la plus petite valeur de $C$ (taille des bacs) qui permet à $T$ d{\textquoteright}être pacqué dans m (ou moins) bacs.

\bigskip
Le but de MULTIFIT est donc de réduire la valeur de $C$, faire tourner $FFD(T,C) $,jusqu{\textquoteright}à ce que le nombre $m$ de bacs, alors devenu insuffisant, augmente à $m+1$.
Cette valeur charnière de $C$ est $T_m^\star$, qui correspond au makespan minimum recherché, de l{\textquoteright}ordonnancement de l{\textquoteright}ensemble $T$ de jobs sur $m$ machine identiques parallèles.



{\centering 
\includegraphics[width=6.138cm,height=7.62cm]{Biblio_PCmax_Rendu_exMULTIFIT1.jpg}
%\includegraphics[width=8.334cm,height=4.034cm]{Biblio_PCmax_Rendu_exMULTIFIT1.jpg}

\par}
{\centering
Fonctionnement de FFD et principe de MULTIFIT
\par}

\bigskip

% Algorithme
% ---------------------
\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{T un ensemble de jobs 

m, un nombre de processeurs 

borne supérieure : $Cu[T,m]~=~max\{\dfrac{2}{m} * L(T), max_i\{L(T_i)\}  \}$

borne inférieure : $Cl[T,m]~=~max\{\dfrac{1}{m} * L(T), max_i\{L(T_i)\} \}$

k un nombre d{\textquoteright}itérations
}

\BlankLine % Petit espace 
La recherche de $T_m^\star$ s{\textquoteright}effectue par dichotomie sur k itérations

\BlankLine % Petit espace 
Après les k itérations, MULTIFIT \textbf{ renvoie $Cu(k)$} qui correspond à la plus petite valeur de $C$ pour laquelle $FFD[T,C] \leq m$

\caption{MULTIFIT\label{MULTIFIT}}
\end{algorithm}

\bigskip

% Complexité
% -------------------------------------------------------
\begin{flushleft}
\begin{tabular}{|p{10cm}p{4cm}|}
% TITRES (pas de titre)
\hline 

% Ligne blanche
 & \\	

% Ligne Complexité
Tri~puis~k FFD~s{\textquoteright}effectuent~en & $O(n log n + kn log m)$
\\	% pas de ligne \hline

% Ligne blanche
 & \\	

% RATIO 
Ratio \cite{lee1988multiprocessor} & $\Gamma(MULTIFIT) \leq 1,220 + 2^{-k}$

\\ 

% Ligne blanche
& \\
\hline
\end{tabular}
%pas de legende
\end{flushleft}

Généralement, MULTIFIT donne des résultats très satisfaisant avec $k~=~7$


\bigskip
% -------------------------------------------------------
% COMBINE
% -------------------------------------------------------
\item \textbf{algorithme COMBINE}


% Présentaion
% ---------------------
Lee \textit{et al.}, \cite{lee1988multiprocessor} ont l'idée d{\textquoteright}utiliser LPT (\ref{LPT}) pour réduire les bornes de départ de MULTIFIT (\ref{MULTIFIT}) dans un algorithme nommé COMBINE.

\bigskip
soient
\begin{align*}
&la~moyenne~des~poids~des~jobs~par~processeur &A &= \sum_{i=1}^{n}(\dfrac{P_i}{m})\\
&et &M &= C_m^lpt(J) \\
& &M^\star &= C_m^\star(J)
\end{align*}
 Si $M \geq 1,5\cdot A$ alors $M^\star ~=~M$
 
\bigskip

% Algorithme
% ---------------------
\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{instance de P\textsubscript{m}{\textbar}{\textbar}C\textsubscript{max}, avec m machines, n jobs, et un coefficient~$\alpha~(0,005)$ }

A = $\sum_{i=1}^{n}(\dfrac{P_i}{m})$

\BlankLine % Petit espace 

M $\leftarrow  C_m^{lpt}(J)$

\BlankLine % Petit espace 

\If {$M \geq 1,5 \cdot A$}
 {
 	$M^\star~=~M$ \;
 }
\Else
 {
	$C_u~\leftarrow~M$					\;
	$C_l~\leftarrow~max \{(\dfrac{M}{\dfrac{4}{3}-\dfrac{1}{3\cdot m}}),P1,1     \}$	\;
	\While {$C_u - C_l > \alpha \cdot A$}
	 {
	 appliquer MULTIFIT \;
	 
	 } \tcp{on arrête lorsque $C_u - C_l \leq \alpha \cdot A$}
 }

\caption{COMBINE\label{COMBINE}}

\end{algorithm}


\bigskip

% Complexité
% -------------------------------------------------------
\begin{flushleft}
\begin{tabular}{|p{10cm}p{4cm}|}
% TITRES (pas de titre)
\hline 

% Ligne blanche
 & \\	

% Ligne Complexité
Conplexité & $O(n log n + kn log m)$
\\	% pas de ligne \hline

% Ligne blanche
 & \\	

% RATIO 
Ratio \cite{gupta2001listfit} & $\Gamma(COMBINE) \leq \dfrac{13}{12} + 2^{-k}$

\\ 

% Ligne blanche
& \\
\hline
\end{tabular}
%pas de legende
\end{flushleft}

avec k le nombre d'itérations pour la recherche dichotomique. 
Concernant la complexité, pour atteindre $C_u - C_l \leq \alpha \cdot A$, généralement, 6 itérations suffisent ($k=6$). Mais COMBINE a déjà exécuté une fois LPT (k=7). 



\bigskip
% -------------------------------------------------------
% LISTFIT
% -------------------------------------------------------
\item \textbf{algorithme LISTFIT}

% Présentaion
% ---------------------
Gupta \textit{et al.}, \cite{gupta2001listfit}, ont aussi l{\textquoteright}idée d{\textquoteright}utiliser MULTIFIT (\ref{MULTIFIT}), afin de réaliser l'olgorithme LISTFIT.

Celui-ci sépare la liste des travaux en 2 sous-listes, traitée soit dans un ordre LPT (Longest Time Processing), soit dans un ordre SPT (Shortest Time Processing). Puis LISTFIT combine ces 2 sous-listes en appliquant MULTIFIT à chaque itération.

\bigskip
% Algorithme
% ---------------------
\begin{algorithm}[H]
\DontPrintSemicolon
\KwData{n,~m,~$p_i$ for $i=1, ..., n$}

%STEP 1
let $r=1$, $q=1$, and $C_{max}=C_{max}(LPT)$, the makespan obtained by the LPT algorithm. \textbf{Goto step 2}.

%STEP 2
\BlankLine % Petit espace 
let $\Phi = \varnothing$, A = $\{1,...,n\}$, and $B = \varnothing$. let $\omega_r$ be the sequence of jobs in job-list A sorted according to ordering $\tau$. \textbf{Goto step 3}.

%STEP 3
\BlankLine % Petit espace 
let $\alpha=C_{max}(MULTIFIT)$ be the makespan obtained by using algorithm MULTIFIT, with $\sigma = \Phi_q \cdot \omega_r$ in step 1 of algorithm MULTIFIT. 
If $C_{max}>\alpha$ then set $C_{max} = \alpha$ and $\gamma_h = \pi_h$ for $h=1,2,...,m$. If $A \neq \varnothing$ then \textbf{goto step 4}; otherwise \textbf{goto step 5}.

%STEP 4
\BlankLine % Petit espace 
remove the last job of $\omega_r$ and place it into $B$. Update $A$, $\Phi_q$ and $\omega_r$. Let $\sigma = \Phi_q \cdot \omega_r$. \textbf{goto step 3}.

%STEP 5
\BlankLine % Petit espace 
If {$\tau < 2$} then set $\tau = \tau + 1$ and	\textbf{goto step 2}; otherwise \textbf{goto step 6}

%STEP 6
\BlankLine % Petit espace 
If $q<2$ then set $q=q+1$, $\tau = 1$, and \textbf{goto step 2}; oterwise \textbf{stop}; \tcp{The schedule where jobs in $\gamma_h$ are proceded on machine $h$ is an approximate solution of the P{\textbar}{\textbar}C\textsubscript{max} problem with makespan $C_{max}$.}

\caption{LISTFIT\label{LISTFIT}}
\end{algorithm}

\bigskip
% Complexité
% -------------------------------------------------------
\begin{flushleft}
\begin{tabular}{|p{10cm}p{4cm}|}
% TITRES (pas de titre)
\hline 

% Ligne blanche
 & \\	

% Ligne Complexité
Conplexité & $O(n^2 log(n) + k \cdot n^2 log(m))$
\\	% pas de ligne \hline

% Ligne blanche
 & \\	

% RATIO 
Ratio \cite{gupta2001listfit} & $\Gamma(LISTFIT) \leq \dfrac{13}{12} + 2^{-k}$

\\ 

% Ligne blanche
& \\
\hline
\end{tabular}
%pas de legende
\end{flushleft}

avec k le nombre d{\textquoteright}itérations pour la recherche dichotomique. 

\end{itemize} 

\subsubsection{Approche gloutonne}

\begin{itemize}

\bigskip
% -------------------------------------------------------
% SLACK
% -------------------------------------------------------
\item \textbf{algorithme SLACK (Croce \textit{et al.}, 2018)}.

% Présentaion
% ---------------------
Croce \textit{et al.} \cite{della2018longest}, en effectuant la preuve d{\textquoteright}une borne d{\textquoteright}approximation pour le développement de LPT-Rev (\ref{LPTRev}), ont mis en évidence l{\textquoteright}importance des différences de temps entre les jobs, ainsi que le regroupement de ceux-ci en sous-ensembles.

notamment pour l{\textquoteright}instance suivante :
% * pour ne pas numéroter. Juste besoin d'aligner 
\begin{align*}	
& Nombre~de~jobs &n &=2 \cdot m + 1			\\
& Avec &P_{2 \cdot m + 1} &\geq P_1 - P_m
\end{align*}
Où ils ont planifié d'abord, le job $2 \cdot m + 1$, puis un sous-ensemble de jobs triés $\{1,...,m\}$ et pour finir un sous-ensemble de jobs triés $\{m+1,...,2 \cdot m \}$  	
	
En résulte l'algorithme suivant :

\bigskip

\bigskip
% Algorithme
% ---------------------
\begin{algorithm}[H]
\DontPrintSemicolon
% \KwData{une instance ...}

%Etape 1
trier la liste des jobs dans l{\textquoteright}ordre décroissant des temps nécessaires de traitements

%ETAPE 2
\BlankLine % Petit espace 
réindexer les jobs, de manière à obtenir $P_1 \geq P_2 \geq ... \geq P_n$

%ETAPE 3
\BlankLine % Petit espace 
Découper l{\textquoteright}ensemble obtenu en $\dfrac{n}{m}$ tuples de $m$ jobs (ajout de jobs "dummy" de taille nulle pour le dernier tuple, si $n$ n{\textquoteright}est pas un multiple de $m$)

%ETAPE 4
\BlankLine % Petit espace 
considérer chaque tuple avec la différence de temps (SLACK) entre le premier job du tuple et le dernier.
\begin{align*}
\{ &\{1, ..., m\} &\{m+1,..., 2 \cdot m\} &... \} \\
   &P_1 - P_m     &P_{m+1}-P_{2 \cdot m}  &...
\end{align*} 


%STEP 5
\BlankLine % Petit espace 
trier les tuples par ordre décroissant de "Slack" et ainsi former un  nouvel ensemble 
\tcp{e.g : $\{ \{m+1,..., 2 \cdot m\} \{1, ..., m\}\}$ si $P_{m+1} - P_{2 \cdot m} >  P_1 - P_m$.}

%STEP 6
\BlankLine % Petit espace 
applique l{\textquoteright}ordonnancement (Affectation à la machine la moins chargée à ce moment là) à l{\textquoteright}ensemble ainsi obtenu.

\caption{SLACK\label{SLACK}}
\end{algorithm}

\end{itemize}

\subsection{Programmation linéaire}





\subsection{Approximation}

\subsection{Autres approches}

\section{Synthèse}

\section{Conclusion}









\medskip


\bibliographystyle{plain}				% NE PAS ENLEVER !!!!!!!!!!
\bibliography{Bibliographie}			% Utilise Bibliographie.bib








\end{document}



